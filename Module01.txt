--虛擬機IP必須為192.168.56.103(建議固定)
--連線到192.168.56.103(HOST)
--登入身分為cloudera,密碼為cloudera
--Cloudera Manager WebUI port: 7180
[cloudera@cdh6 ~]$ id
uid=501(cloudera) gid=501(cloudera) groups=501(cloudera),502(default)

[cloudera@cdh6 ~]$ jps
22888 Jps

--$ sudo jps讓cloudera使用者暫時使用root身分執行jps指令,列表目前所有執行中的java processes
[cloudera@cdh6 ~]$ su - root
Password:
Last login: Tue Sep  8 21:08:20 CST 2020 on pts/1

[root@cdh6 ~]# jps
4960 Main
4417 DataNode
4419 SecondaryNameNode
5252 AlertPublisher
4356 HttpFSServerWebServer
3268 RunJar
4937 EventCatcherService
3050 NodeManager
3820 Jps
3309 RunJar
1230 Main
4814 Main
4880 Main
4433 NameNode
3857
7089
5364 HeadlampServer
3035 ResourceManager
4092 QuorumPeerMain
3037 JobHistoryServer

--此範例機器採用偽分佈式(pesudo distributed)
                                  
[root@cdh6 ~]# ps -ef | grep 4433
hdfs      4064  1195  0 09:05 ?        00:00:01 /usr/bin/python2 /opt/cloudera/cm-agent/bin/cm proc_watcher 4433
root      4316  3720  0 13:13 pts/0    00:00:00 grep --color=auto 4433
hdfs      4433  4064  0 09:05 ?        00:01:31 /usr/java/jdk1.8.0_232-cloudera/bin/java -Dproc_namenode -Dhdfs.audit.logger=INFO,RFAAUDIT -Dsecurity.audit.logger=INFO,RFAS -Djava.net.preferIPv4Stack=true -Xms955252736 -Xmx955252736 -XX:+UseParNewGC -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=/tmp/hdfs_hdfs-NAMENODE-6c57b1a598e149581e1d58acf4880987_pid4433.hprof -XX:OnOutOfMemoryError=/opt/cloudera/cm-agent/service/common/killparent.sh -Dyarn.log.dir=/var/log/hadoop-hdfs -Dyarn.log.file=hadoop-cmf-hdfs-NAMENODE-cdh6.log.out -Dyarn.home.dir=/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-yarn -Dyarn.root.logger=INFO,console -Djava.library.path=/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/native -Dhadoop.log.dir=/var/log/hadoop-hdfs -Dhadoop.log.file=hadoop-cmf-hdfs-NAMENODE-cdh6.log.out -Dhadoop.home.dir=/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop -Dhadoop.id.str=hdfs -Dhadoop.root.logger=INFO,RFA -Dhadoop.policy.file=hadoop-policy.xml -Dhadoop.security.logger=INFO,RFAS org.apache.hadoop.hdfs.server.namenode.NameNode
                                                                                           -------------
--core hadoop(mapreduce,hdfs)設定檔,設定檔為xml格式
[cloudera@cdh6 ~]$ ls -l /etc/hadoop/conf/
total 48
-rw-r--r-- 1 root root     20 Jun 27 20:11 __cloudera_generation__
-rw-r--r-- 1 root root     67 Jun 27 20:11 __cloudera_metadata__
-r-------- 1 root hadoop    0 Sep 22 18:22 container-executor.cfg
-rw-r--r-- 1 root root   3862 Jun 27 20:11 core-site.xml
-rw-r--r-- 1 root root    616 Jun 27 20:11 hadoop-env.sh
-rw-r--r-- 1 root root   1772 Jun 27 20:11 hdfs-site.xml
-rw-r--r-- 1 root root    314 Jun 27 20:11 log4j.properties
-rw-r--r-- 1 root root   5101 Jun 27 20:11 mapred-site.xml
-rw-r--r-- 1 root root    315 Jun 27 20:11 ssl-client.xml
-rw-r--r-- 1 root hadoop  200 Sep 22 19:00 topology.map
-rwxr-xr-x 1 root hadoop 1594 Sep 22 19:00 topology.py
-rw-r--r-- 1 root root   3608 Jun 27 20:11 yarn-site.xml

--可以使用text editor修改相關設定檔,但必須重新啟動相關元件已生效變更(如果修改worker node設定,需要同步所有worker node設定檔內容與重新啟動)
[cloudera@cdh6 ~]$ cat /etc/hadoop/conf/hdfs-site.xml
<?xml version="1.0" encoding="UTF-8"?>

<!--Autogenerated by Cloudera Manager-->
<configuration>
  <property>
    <name>dfs.namenode.name.dir</name>
    <value>file:///var/lib/hadoop-hdfs/cache/hdfs/dfs/name</value>
  </property>
  <property>
    <name>dfs.namenode.servicerpc-address</name>
    <value>cdh6:8022</value>
  </property>
  <property>
    <name>dfs.https.address</name>
    <value>cdh6:50470</value>
  </property>
  <property>
    <name>dfs.https.port</name>
    <value>50470</value>
  </property>
  <property>
    <name>dfs.namenode.http-address</name>
    <value>cdh6:50070</value>
  </property>
  <property>
    <name>dfs.replication</name>
    <value>1</value>
  </property>
  <property>
    <name>dfs.blocksize</name>
    <value>134217728</value>
  </property>
  <property>
    <name>dfs.client.use.datanode.hostname</name>
    <value>false</value>
  </property>
  <property>
    <name>fs.permissions.umask-mode</name>
    <value>022</value>
  </property>
  <property>
    <name>dfs.namenode.acls.enabled</name>
    <value>false</value>
  </property>
  <property>
    <name>dfs.client.use.legacy.blockreader</name>
    <value>false</value>
  </property>
  <property>
    <name>dfs.client.read.shortcircuit</name>
    <value>false</value>
  </property>
  <property>
    <name>dfs.domain.socket.path</name>
    <value>/var/run/hdfs-sockets/dn</value>
  </property>
  <property>
    <name>dfs.client.read.shortcircuit.skip.checksum</name>
    <value>false</value>
  </property>
  <property>
    <name>dfs.client.domain.socket.data.traffic</name>
    <value>false</value>
  </property>
  <property>
    <name>dfs.datanode.hdfs-blocks-metadata.enabled</name>
    <value>true</value>
  </property>
</configuration>

--因為只有一個data node,所以將replication factor設為1,預設值應該為3
[cloudera@cdh6 conf]$ cat hdfs-site.xml | grep dfs.replication -B 1 -A 2
  <property>
    <name>dfs.replication</name>
    <value>1</value>
  </property>

--顯示目前登入的os user資訊
[cloudera@cdh6 ~]$ id
uid=1000(cloudera) gid=1000(cloudera) groups=1000(cloudera),10(wheel)

--顯示本地端檔案系統
[cloudera@cdh6 ~]$ ls -l
total 244260
              --owner  group  
-rwx------  1 cloudera cloudera   2370789 Sep  7 21:35 apache_logs.txt
-rwx------  1 cloudera cloudera     31861 Sep  7 21:17 Boston.csv
-rw-rw-r--  1 cloudera cloudera     29129 Sep  4 16:13 customers.java
-rwx------  1 cloudera cloudera        38 Sep  7 21:36 data.txt
-rwx------  1 cloudera cloudera        79 Sep  7 21:17 dept1.csv
-rwx------  1 cloudera cloudera       120 Sep  7 21:17 dept.csv
drwxr-xr-x. 2 cloudera cloudera         6 Aug 12 13:17 Desktop
drwxr-xr-x. 2 cloudera cloudera         6 Aug 12 11:54 Documents
drwxr-xr-x. 2 cloudera cloudera         6 Aug 12 11:54 Downloads
-rwx------  1 cloudera cloudera       617 Sep  7 21:17 emp1.csv
-rwx------  1 cloudera cloudera       665 Sep  7 21:17 emp.csv
-rwx------  1 cloudera cloudera      2082 Sep  7 21:34 emp.parquet
-rwx------  1 cloudera cloudera        60 Sep  7 21:23 frank.json
-rwx------  1 cloudera cloudera        51 Sep  7 21:23 jack.json
-rwx------  1 cloudera cloudera     84697 Sep  7 21:35 java-json.jar
drwxr-xr-x. 2 cloudera cloudera         6 Aug 12 11:54 Music
-rwx------  1 cloudera cloudera        78 Sep  7 21:23 people.json
-rwx------  1 cloudera cloudera    121627 Sep  4 14:02 pg1778.txt
drwxr-xr-x. 2 cloudera cloudera         6 Aug 12 11:54 Pictures
drwxr-xr-x. 2 cloudera cloudera         6 Aug 12 11:54 Public
-rw-r--r--  1 cloudera cloudera  10303297 Sep  4 14:23 retail_db.sql
-rwx------  1 cloudera cloudera    119069 Sep  7 21:34 sample_linear_regression_data.txt
-rwx------  1 cloudera cloudera   5436535 Sep  4 13:57 shakespeare.txt
-rw-rw-r--  1 cloudera cloudera 227893062 Oct 29  2018 spark-2.4.0-bin-hadoop2.7.tgz
drwxr-xr-x. 2 cloudera cloudera         6 Aug 12 11:54 Templates
-rw-r--r--  1 cloudera cloudera   3677118 Sep  7 21:36 TL.txt
drwxr-xr-x. 2 cloudera cloudera         6 Aug 12 11:54 Videos

                owner    group
-表示為檔案
d表示為目錄

owner group other
  rwx   rwx   rwx

--hdfs是一個utility,用來操作Hadoop Distributed FileSystem
[cloudera@cdh6 ~]$ hdfs
Usage: hdfs [OPTIONS] SUBCOMMAND [SUBCOMMAND OPTIONS]

  OPTIONS is none or any of:

--buildpaths                       attempt to add class files from build tree
--config dir                       Hadoop config directory
--daemon (start|status|stop)       operate on a daemon
--debug                            turn on shell script debug mode
--help                             usage information
--hostnames list[,of,host,names]   hosts to use in worker mode
--hosts filename                   list of hosts to use in worker mode
--loglevel level                   set the log4j level for this command
--workers                          turn on worker mode

  SUBCOMMAND is one of:


    Admin Commands:

cacheadmin           configure the HDFS cache
crypto               configure HDFS encryption zones
debug                run a Debug Admin to execute HDFS debug commands
dfsadmin             run a DFS admin client
dfsrouteradmin       manage Router-based federation
ec                   run a HDFS ErasureCoding CLI
fsck                 run a DFS filesystem checking utility
haadmin              run a DFS HA admin client
jmxget               get JMX exported values from NameNode or DataNode.
oev                  apply the offline edits viewer to an edits file
oiv                  apply the offline fsimage viewer to an fsimage
oiv_legacy           apply the offline fsimage viewer to a legacy fsimage
storagepolicies      list/get/set block storage policies

    Client Commands:

classpath            prints the class path needed to get the hadoop jar and the required libraries
dfs                  run a filesystem command on the file system
envvars              display computed Hadoop environment variables
fetchdt              fetch a delegation token from the NameNode
getconf              get config values from configuration
groups               get the groups which users belong to
lsSnapshottableDir   list all snapshottable dirs owned by the current user
snapshotDiff         diff two snapshots of a directory or diff the current directory contents with a snapshot
version              print the version

    Daemon Commands:

balancer             run a cluster balancing utility
datanode             run a DFS datanode
dfsrouter            run the DFS router
diskbalancer         Distributes data evenly among disks on a given node
httpfs               run HttpFS server, the HDFS HTTP Gateway
journalnode          run the DFS journalnode
mover                run a utility to move block replicas across storage types
namenode             run the DFS namenode
nfs3                 run an NFS version 3 gateway
portmap              run a portmap service
secondarynamenode    run the DFS secondary namenode
zkfc                 run the ZK Failover Controller daemon

SUBCOMMAND may print help when invoked w/o parameters or with -h.

--hdfs dfs使用hdfs工具對HDFS進行客戶端操作
[cloudera@cdh6 ~]$ hdfs dfs
Usage: hadoop fs [generic options]
        [-appendToFile <localsrc> ... <dst>]
        [-cat [-ignoreCrc] <src> ...]
        [-checksum <src> ...]
        [-chgrp [-R] GROUP PATH...]
        [-chmod [-R] <MODE[,MODE]... | OCTALMODE> PATH...]
        [-chown [-R] [OWNER][:[GROUP]] PATH...]
        [-copyFromLocal [-f] [-p] [-l] [-d] [-t <thread count>] <localsrc> ... <dst>]
        [-copyToLocal [-f] [-p] [-ignoreCrc] [-crc] <src> ... <localdst>]
        [-count [-q] [-h] [-v] [-t [<storage type>]] [-u] [-x] [-e] <path> ...]
        [-cp [-f] [-p | -p[topax]] [-d] <src> ... <dst>]
        [-createSnapshot <snapshotDir> [<snapshotName>]]
        [-deleteSnapshot <snapshotDir> <snapshotName>]
        [-df [-h] [<path> ...]]
        [-du [-s] [-h] [-v] [-x] <path> ...]
        [-expunge]
        [-find <path> ... <expression> ...]
        [-get [-f] [-p] [-ignoreCrc] [-crc] <src> ... <localdst>]
        [-getfacl [-R] <path>]
        [-getfattr [-R] {-n name | -d} [-e en] <path>]
        [-getmerge [-nl] [-skip-empty-file] <src> <localdst>]
        [-help [cmd ...]]
        [-ls [-C] [-d] [-h] [-q] [-R] [-t] [-S] [-r] [-u] [-e] [<path> ...]]
        [-mkdir [-p] <path> ...]
        [-moveFromLocal <localsrc> ... <dst>]
        [-moveToLocal <src> <localdst>]
        [-mv <src> ... <dst>]
        [-put [-f] [-p] [-l] [-d] <localsrc> ... <dst>]
        [-renameSnapshot <snapshotDir> <oldName> <newName>]
        [-rm [-f] [-r|-R] [-skipTrash] [-safely] <src> ...]
        [-rmdir [--ignore-fail-on-non-empty] <dir> ...]
        [-setfacl [-R] [{-b|-k} {-m|-x <acl_spec>} <path>]|[--set <acl_spec> <path>]]
        [-setfattr {-n name [-v value] | -x name} <path>]
        [-setrep [-R] [-w] <rep> <path> ...]
        [-stat [format] <path> ...]
        [-tail [-f] <file>]
        [-test -[defsz] <path>]
        [-text [-ignoreCrc] <src> ...]
        [-touch [-a] [-m] [-t TIMESTAMP ] [-c] <path> ...]
        [-touchz <path> ...]
        [-truncate [-w] <length> <path> ...]
        [-usage [cmd ...]]

Generic options supported are:
-conf <configuration file>        specify an application configuration file
-D <property=value>               define a value for a given property
-fs <file:///|hdfs://namenode:port> specify default filesystem URL to use, overrides 'fs.defaultFS' property from configurations.
-jt <local|resourcemanager:port>  specify a ResourceManager
-files <file1,...>                specify a comma-separated list of files to be copied to the map reduce cluster
-libjars <jar1,...>               specify a comma-separated list of jar files to be included in the classpath
-archives <archive1,...>          specify a comma-separated list of archives to be unarchived on the compute machines

The general command line syntax is:
command [genericOptions] [commandOptions]

--如果-ls後面沒有加上任何HDFS目錄名字,則自動顯示家目錄(home directory),誰的家?
--目前執行hdfs工具的os user
[cloudera@cdh6 ~]$ hdfs dfs -ls
Found 4 items
drwx------   - cloudera supergroup          0 2020-09-14 10:00 .Trash
drwxr-xr-x   - cloudera supergroup          0 2020-09-08 21:07 .sparkStaging
drwx------   - cloudera supergroup          0 2020-09-08 17:13 .staging
-rw-r--r--   1 cloudera supergroup        617 2020-09-08 15:09 emp1.csv

--顯示HDFS根目錄
[cloudera@cdh6 ~]$ hdfs dfs -ls /
Found 2 items
drwxrwxrwt   - hdfs supergroup          0 2020-09-03 16:31 /tmp
drwxr-xr-x   - hdfs supergroup          0 2020-09-04 16:48 /user

--顯示HDFS的/user子目錄
[cloudera@cdh6 ~]$ hdfs dfs -ls /user/
Found 9 items
drwxr-xr-x   - admin    admin               0 2020-09-03 16:32 /user/admin
drwxr-xr-x   - cloudera supergroup          0 2020-09-08 15:09 /user/cloudera
drwx------   - hdfs     supergroup          0 2020-09-04 16:48 /user/hdfs
drwxrwxrwx   - mapred   hadoop              0 2020-09-03 10:32 /user/history
drwxrwxr-t   - hive     hive                0 2020-09-03 13:45 /user/hive
drwxrwxr-x   - hue      hue                 0 2020-09-03 13:46 /user/hue
drwxrwxr-x   - impala   impala              0 2020-09-04 14:08 /user/impala
drwxr-x--x   - spark    spark               0 2020-09-03 10:38 /user/spark
drwxr-xr-x   - hdfs     supergroup          0 2020-09-03 10:31 /user/yarn

--顯示HDFS的/user/cloudera子目錄,其結果與hdfs dfs -ls相同,但僅限於執行hdfs工具的os user為cloudera時
[cloudera@cdh6 ~]$ hdfs dfs -ls /user/cloudera
Found 4 items
drwx------   - cloudera supergroup          0 2020-09-14 10:00 /user/cloudera/.Trash
drwxr-xr-x   - cloudera supergroup          0 2020-09-08 21:07 /user/cloudera/.sparkStaging
drwx------   - cloudera supergroup          0 2020-09-08 17:13 /user/cloudera/.staging
-rw-r--r--   1 cloudera supergroup        617 2020-09-08 15:09 /user/cloudera/emp1.csv

\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\
--請注意目前登入的os user為root
[root@cdh6 ~]# hdfs dfs -ls
ls: `.': No such file or directory    --因為所查詢的HDFS目錄為/user/root/

[root@cdh6 ~]# hdfs dfs -ls /
Found 2 items
drwxrwxrwt   - hdfs supergroup          0 2020-09-03 16:31 /tmp
drwxr-xr-x   - hdfs supergroup          0 2020-09-04 16:48 /user
\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\
[cloudera@cdh6 ~]$ pwd
/home/cloudera
[cloudera@cdh6 ~]$ hdfs dfs -put spark-2.4.0-bin-hadoop2.7.tgz
                                 -----------------------------
								 local file                     hdfs file
                -- hdfs dfs -put spark-2.4.0-bin-hadoop2.7.tgz /user/cloudera/spark-2.4.0-bin-hadoop2.7.tgz

[cloudera@cdh6 ~]$ hdfs dfs -put spark-2.4.0-bin-hadoop2.7.tgz /tmp/spark2.4.tgz

[cloudera@cdh6 ~]$ hdfs dfs -ls
Found 5 items
drwx------   - cloudera supergroup          0 2020-09-14 10:00 .Trash
drwxr-xr-x   - cloudera supergroup          0 2020-09-08 21:07 .sparkStaging
drwx------   - cloudera supergroup          0 2020-09-08 17:13 .staging
-rw-r--r--   1 cloudera supergroup        617 2020-09-08 15:09 emp1.csv
-rw-r--r--   1 cloudera supergroup  227893062 2020-09-14 13:42 spark-2.4.0-bin-hadoop2.7.tgz
                                    ---------
									200M(預設HDFS blocksize若為128M,則此檔案將被分成2個HDFS block)
[cloudera@cdh6 ~]$ hdfs dfs -ls /user/cloudera/
Found 5 items
drwx------   - cloudera supergroup          0 2020-09-14 10:00 /user/cloudera/.Trash
drwxr-xr-x   - cloudera supergroup          0 2020-09-08 21:07 /user/cloudera/.sparkStaging
drwx------   - cloudera supergroup          0 2020-09-08 17:13 /user/cloudera/.staging
-rw-r--r--   1 cloudera supergroup        617 2020-09-08 15:09 /user/cloudera/emp1.csv
-rw-r--r--   1 cloudera supergroup  227893062 2020-09-14 13:42 /user/cloudera/spark-2.4.0-bin-hadoop2.7.tgz

--顯示HDFS file的組成區塊
[cloudera@cdh6 ~]$ hdfs fsck -blocks -files /user/cloudera/spark-2.4.0-bin-hadoop2.7.tgz
Connecting to namenode via http://cdh6:9870/fsck?ugi=cloudera&blocks=1&files=1&path=%2Fuser%2Fcloudera%2Fspark-2.4.0-bin-hadoop2.7.tgz
FSCK started by cloudera (auth:SIMPLE) from /192.168.56.103 for path /user/cloudera/spark-2.4.0-bin-hadoop2.7.tgz at Mon Sep 14 13:47:30 CST 2020
/user/cloudera/spark-2.4.0-bin-hadoop2.7.tgz 227893062 bytes, replicated: replication=1, 2 block(s):  OK
0. BP-343982396-192.168.56.103-1599099880694:blk_1073743809_2985 len=134217728 Live_repl=1
1. BP-343982396-192.168.56.103-1599099880694:blk_1073743810_2986 len=93675334 Live_repl=1


Status: HEALTHY
 Number of data-nodes:  1
 Number of racks:               1
 Total dirs:                    0
 Total symlinks:                0

Replicated Blocks:
 Total size:    227893062 B
 Total files:   1
 Total blocks (validated):      2 (avg. block size 113946531 B)
 Minimally replicated blocks:   2 (100.0 %)
 Over-replicated blocks:        0 (0.0 %)
 Under-replicated blocks:       0 (0.0 %)
 Mis-replicated blocks:         0 (0.0 %)
 Default replication factor:    1
 Average block replication:     1.0
 Missing blocks:                0
 Corrupt blocks:                0
 Missing replicas:              0 (0.0 %)
 Blocks queued for replication: 0

Erasure Coded Block Groups:
 Total size:    0 B
 Total files:   0
 Total block groups (validated):        0
 Minimally erasure-coded block groups:  0
 Over-erasure-coded block groups:       0
 Under-erasure-coded block groups:      0
 Unsatisfactory placement block groups: 0
 Average block group size:      0.0
 Missing block groups:          0
 Corrupt block groups:          0
 Missing internal blocks:       0
 Blocks queued for replication: 0
FSCK ended at Mon Sep 14 13:47:30 CST 2020 in 1 milliseconds


The filesystem under path '/user/cloudera/spark-2.4.0-bin-hadoop2.7.tgz' is HEALTHY
				
--NameNode Metadata的存放位置(預設為/dfs/nn)
[root@cdh6 ~]# cat /etc/hadoop/conf/hdfs-site.xml | grep name.dir -B 1 -A 2
  <property>
    <name>dfs.namenode.name.dir</name>
    <value>file:///dfs/nn</value>
  </property>

[root@cdh6 ~]# tree /dfs/nn
/dfs/nn
|-- current
|   |-- edits_0000000000000000001-0000000000000000005
|   |-- edits_0000000000000000006-0000000000000000006
|   |-- edits_0000000000000000007-0000000000000000008
|   |-- edits_0000000000000000009-0000000000000000043
|   |-- edits_0000000000000000044-0000000000000000052
|   |-- edits_0000000000000000053-0000000000000000215
|   |-- edits_0000000000000000216-0000000000000000682
|   |-- edits_0000000000000000683-0000000000000001231
|   |-- edits_0000000000000001232-0000000000000001811
|   |-- edits_0000000000000001812-0000000000000002163
|   |-- edits_0000000000000002164-0000000000000002516
|   |-- edits_0000000000000002517-0000000000000003052
|   |-- edits_0000000000000003053-0000000000000003425
|   |-- edits_0000000000000003426-0000000000000003814
|   |-- edits_0000000000000003815-0000000000000004350
|   |-- edits_0000000000000004351-0000000000000004813
|   |-- edits_0000000000000004814-0000000000000004815
|   |-- edits_0000000000000004816-0000000000000005342
|   |-- edits_0000000000000005343-0000000000000005879
|   |-- edits_0000000000000005880-0000000000000008013
|   |-- edits_0000000000000008014-0000000000000008557
|   |-- edits_0000000000000008558-0000000000000008658
|   |-- edits_0000000000000008659-0000000000000008783
|   |-- edits_0000000000000008784-0000000000000009754
|   |-- edits_0000000000000009755-0000000000000010630
|   |-- edits_0000000000000010631-0000000000000011227
|   |-- edits_0000000000000011228-0000000000000012496
|   |-- edits_0000000000000012497-0000000000000013028
|   |-- edits_0000000000000013029-0000000000000013564
|   |-- edits_0000000000000013565-0000000000000014349
|   |-- edits_0000000000000014350-0000000000000014884
|   |-- edits_0000000000000014885-0000000000000015420
|   |-- edits_0000000000000015421-0000000000000015956
|   |-- edits_0000000000000015957-0000000000000016492
|   |-- edits_0000000000000016493-0000000000000017056
|   |-- edits_0000000000000017057-0000000000000017627
|   |-- edits_inprogress_0000000000000017628              --17627之後對NameNode metadata所產生的異動紀錄
|   |-- fsimage_0000000000000017056
|   |-- fsimage_0000000000000017056.md5
|   |-- fsimage_0000000000000017627　　　　　　　　　　　 --NameNode metadata在17627當時的所有內容
|   |-- fsimage_0000000000000017627.md5
|   |-- seen_txid
|   `-- VERSION
`-- in_use.lock

1 directory, 44 files

--備份NameNode Metadata
[cloudera@cdh6 ~]$ hdfs dfsadmin -fetchImage /tmp/
20/09/14 15:37:23 INFO namenode.TransferFsImage: Opening connection to http://cdh6:9870/imagetransfer?getimage=1&txid=latest
20/09/14 15:37:23 INFO common.Util: Combined time for file download and fsync to all disks took 0.00s. The file download took 0.00s at 24500.00 KB/s. Synchronous (fsync) write to disk of /tmp/fsimage_0000000000000017627 took 0.00s.

[cloudera@cdh6 ~]$ ls -l /tmp/fsimage_0000000000000017627
-rw-rw-r-- 1 cloudera cloudera 50752 Sep 14 15:37 /tmp/fsimage_0000000000000017627

                   os指令暫時切換os user身分為hdfs,hdfs這個os user預設為HDFS的SUPERUSER
                   ------------
[cloudera@cdh6 ~]$ sudo -u hdfs hdfs dfs -ls
[sudo] password for cloudera: cloudera
Found 1 items
drwx------   - hdfs supergroup          0 2020-09-07 22:00 .Trash

[cloudera@cdh6 ~]$ sudo jps | grep DataNode
3429 DataNode
[cloudera@cdh6 ~]$ ps -ef | grep 3429
hdfs      3429  2211  0 18:22 ?        00:00:50 /usr/java/jdk1.8.0_211/bin/java -Dproc_datanode -Xmx1000m -Dhdfs.audit.logger=INFO,RFAAUDIT -Dsecurity.audit.logger=INFO,RFAS -Djava.net.preferIPv4Stack=true -Dhadoop.log.dir=/var/log/hadoop-hdfs -Dhadoop.log.file=hadoop-cmf-hdfs-DATANODE-cdh6.log.out -Dhadoop.home.dir=/opt/cloudera/parcels/CDH-5.13.0-1.cdh5.13.0.p0.29/lib/hadoop -Dhadoop.id.str=hdfs -Dhadoop.root.logger=INFO,RFA -Djava.library.path=/opt/cloudera/parcels/CDH-5.13.0-1.cdh5.13.0.p0.29/lib/hadoop/lib/native -Dhadoop.policy.file=hadoop-policy.xml -Djava.net.preferIPv4Stack=true -server -Xms52428800 -Xmx52428800 -XX:+UseParNewGC -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=/tmp/hdfs_hdfs-DATANODE_pid3429.hprof -XX:OnOutOfMemoryError=/usr/lib64/cmf/service/common/killparent.sh -Dhadoop.security.logger=INFO,RFAS org.apache.hadoop.hdfs.server.datanode.DataNode
hdfs      3493  3429  0 18:22 ?        00:00:00 python2.6 /usr/lib64/cmf/agent/build/env/bin/cmf-redactor /usr/lib64/cmf/service/hdfs/hdfs.sh datanode
cloudera 15721  8824  0 22:39 pts/0    00:00:00 grep 3429

NameNode High Availability
NameNode(Active) <-> NameNode(Standby)
Cloudera Manager -> HDFS -> Actions -> Enable High Availability

--DataNode資料(HDFS block)的存放位置,預設放在/dfs/dn
[cloudera@cdh6 ~]$ ls -l /dfs/dn
total 8
drwxr-xr-x 3 hdfs hadoop 4096 Oct 23  2017 current
-rw-r--r-- 1 hdfs hdfs     25 Sep 22 22:46 in_use.lock

[root@cdh6 ~]# tree /dfs/dn
/dfs/dn
|-- current
|   |-- BP-343982396-192.168.56.103-1599099880694
|   |   |-- current
|   |   |   |-- dfsUsed
|   |   |   |-- finalized
|   |   |   |   `-- subdir0
|   |   |   |       |-- subdir0
|   |   |   |       |   |-- blk_1073741825
|   |   |   |       |   |-- blk_1073741825_1001.meta
|   |   |   |       |   |-- blk_1073741826
|   |   |   |       |   |-- blk_1073741826_1002.meta
|   |   |   |       |   |-- blk_1073742030
|   |   |   |       |   |-- blk_1073742030_1206.meta
|   |   |   |       |   |-- blk_1073742031
|   |   |   |       |   |-- blk_1073742031_1207.meta
|   |   |   |       |   |-- blk_1073742042
|   |   |   |       |   |-- blk_1073742042_1218.meta
|   |   |   |       |   |-- blk_1073742043
|   |   |   |       |   |-- blk_1073742043_1219.meta
|   |   |   |       |   |-- blk_1073742045
|   |   |   |       |   |-- blk_1073742045_1221.meta
|   |   |   |       |   |-- blk_1073742046
|   |   |   |       |   |-- blk_1073742046_1222.meta
|   |   |   |       |   |-- blk_1073742047
|   |   |   |       |   |-- blk_1073742047_1223.meta
|   |   |   |       |   |-- blk_1073742048
|   |   |   |       |   |-- blk_1073742048_1224.meta
|   |   |   |       |   |-- blk_1073742063
|   |   |   |       |   |-- blk_1073742063_1239.meta
|   |   |   |       |   |-- blk_1073742064
|   |   |   |       |   |-- blk_1073742064_1240.meta
|   |   |   |       |   |-- blk_1073742065
|   |   |   |       |   `-- blk_1073742065_1241.meta
|   |   |   |       |-- subdir1
|   |   |   |       |-- subdir2
|   |   |   |       |   |-- blk_1073742559
|   |   |   |       |   |-- blk_1073742559_1735.meta
|   |   |   |       |   |-- blk_1073742560
|   |   |   |       |   |-- blk_1073742560_1736.meta
|   |   |   |       |   |-- blk_1073742561
|   |   |   |       |   `-- blk_1073742561_1737.meta
|   |   |   |       |-- subdir3
|   |   |   |       |   |-- blk_1073742664
|   |   |   |       |   |-- blk_1073742664_1840.meta
|   |   |   |       |   |-- blk_1073742665
|   |   |   |       |   |-- blk_1073742665_1841.meta
|   |   |   |       |   |-- blk_1073742666
|   |   |   |       |   |-- blk_1073742666_1842.meta
|   |   |   |       |   |-- blk_1073742741
|   |   |   |       |   |-- blk_1073742741_1917.meta
|   |   |   |       |   |-- blk_1073742742
|   |   |   |       |   |-- blk_1073742742_1918.meta
|   |   |   |       |   |-- blk_1073742743
|   |   |   |       |   |-- blk_1073742743_1919.meta
|   |   |   |       |   |-- blk_1073742773
|   |   |   |       |   |-- blk_1073742773_1949.meta
|   |   |   |       |   |-- blk_1073742774
|   |   |   |       |   |-- blk_1073742774_1950.meta
|   |   |   |       |   |-- blk_1073742775
|   |   |   |       |   |-- blk_1073742775_1951.meta
|   |   |   |       |   |-- blk_1073742820
|   |   |   |       |   |-- blk_1073742820_1996.meta
|   |   |   |       |   |-- blk_1073742821
|   |   |   |       |   |-- blk_1073742821_1997.meta
|   |   |   |       |   |-- blk_1073742823
|   |   |   |       |   `-- blk_1073742823_1999.meta
|   |   |   |       |-- subdir4
|   |   |   |       |   |-- blk_1073742930
|   |   |   |       |   |-- blk_1073742930_2106.meta
|   |   |   |       |   |-- blk_1073742931
|   |   |   |       |   |-- blk_1073742931_2107.meta
|   |   |   |       |   |-- blk_1073742932
|   |   |   |       |   |-- blk_1073742932_2108.meta
|   |   |   |       |   |-- blk_1073742956
|   |   |   |       |   |-- blk_1073742956_2132.meta
|   |   |   |       |   |-- blk_1073742957
|   |   |   |       |   |-- blk_1073742957_2133.meta
|   |   |   |       |   |-- blk_1073742958
|   |   |   |       |   |-- blk_1073742958_2134.meta
|   |   |   |       |   |-- blk_1073742961
|   |   |   |       |   |-- blk_1073742961_2137.meta
|   |   |   |       |   |-- blk_1073742962
|   |   |   |       |   |-- blk_1073742962_2138.meta
|   |   |   |       |   |-- blk_1073742963
|   |   |   |       |   |-- blk_1073742963_2139.meta
|   |   |   |       |   |-- blk_1073742964
|   |   |   |       |   |-- blk_1073742964_2140.meta
|   |   |   |       |   |-- blk_1073742965
|   |   |   |       |   |-- blk_1073742965_2141.meta
|   |   |   |       |   |-- blk_1073742966
|   |   |   |       |   |-- blk_1073742966_2142.meta
|   |   |   |       |   |-- blk_1073742992
|   |   |   |       |   |-- blk_1073742992_2168.meta
|   |   |   |       |   |-- blk_1073743021
|   |   |   |       |   |-- blk_1073743021_2197.meta
|   |   |   |       |   |-- blk_1073743022
|   |   |   |       |   |-- blk_1073743022_2198.meta
|   |   |   |       |   |-- blk_1073743023
|   |   |   |       |   |-- blk_1073743023_2199.meta
|   |   |   |       |   |-- blk_1073743053
|   |   |   |       |   |-- blk_1073743053_2229.meta
|   |   |   |       |   |-- blk_1073743063
|   |   |   |       |   |-- blk_1073743063_2239.meta
|   |   |   |       |   |-- blk_1073743064
|   |   |   |       |   |-- blk_1073743064_2240.meta
|   |   |   |       |   |-- blk_1073743066
|   |   |   |       |   |-- blk_1073743066_2242.meta
|   |   |   |       |   |-- blk_1073743074
|   |   |   |       |   `-- blk_1073743074_2250.meta
|   |   |   |       |-- subdir5
|   |   |   |       |   |-- blk_1073743109
|   |   |   |       |   |-- blk_1073743109_2285.meta
|   |   |   |       |   |-- blk_1073743110
|   |   |   |       |   |-- blk_1073743110_2286.meta
|   |   |   |       |   |-- blk_1073743144
|   |   |   |       |   |-- blk_1073743144_2320.meta
|   |   |   |       |   |-- blk_1073743155
|   |   |   |       |   |-- blk_1073743155_2331.meta
|   |   |   |       |   |-- blk_1073743156
|   |   |   |       |   |-- blk_1073743156_2332.meta
|   |   |   |       |   |-- blk_1073743161
|   |   |   |       |   |-- blk_1073743161_2337.meta
|   |   |   |       |   |-- blk_1073743163
|   |   |   |       |   |-- blk_1073743163_2339.meta
|   |   |   |       |   |-- blk_1073743164
|   |   |   |       |   |-- blk_1073743164_2340.meta
|   |   |   |       |   |-- blk_1073743172
|   |   |   |       |   |-- blk_1073743172_2348.meta
|   |   |   |       |   |-- blk_1073743176
|   |   |   |       |   |-- blk_1073743176_2352.meta
|   |   |   |       |   |-- blk_1073743177
|   |   |   |       |   |-- blk_1073743177_2353.meta
|   |   |   |       |   |-- blk_1073743180
|   |   |   |       |   |-- blk_1073743180_2356.meta
|   |   |   |       |   |-- blk_1073743203
|   |   |   |       |   |-- blk_1073743203_2379.meta
|   |   |   |       |   |-- blk_1073743204
|   |   |   |       |   |-- blk_1073743204_2380.meta
|   |   |   |       |   |-- blk_1073743205
|   |   |   |       |   |-- blk_1073743205_2381.meta
|   |   |   |       |   |-- blk_1073743231
|   |   |   |       |   |-- blk_1073743231_2407.meta
|   |   |   |       |   |-- blk_1073743272
|   |   |   |       |   |-- blk_1073743272_2448.meta
|   |   |   |       |   |-- blk_1073743273
|   |   |   |       |   |-- blk_1073743273_2449.meta
|   |   |   |       |   |-- blk_1073743274
|   |   |   |       |   |-- blk_1073743274_2450.meta
|   |   |   |       |   |-- blk_1073743282
|   |   |   |       |   |-- blk_1073743282_2458.meta
|   |   |   |       |   |-- blk_1073743287
|   |   |   |       |   |-- blk_1073743287_2463.meta
|   |   |   |       |   |-- blk_1073743296
|   |   |   |       |   |-- blk_1073743296_2472.meta
|   |   |   |       |   |-- blk_1073743309
|   |   |   |       |   `-- blk_1073743309_2485.meta
|   |   |   |       |-- subdir6
|   |   |   |       |   |-- blk_1073743477
|   |   |   |       |   |-- blk_1073743477_2653.meta
|   |   |   |       |   |-- blk_1073743501
|   |   |   |       |   |-- blk_1073743501_2677.meta
|   |   |   |       |   |-- blk_1073743532
|   |   |   |       |   `-- blk_1073743532_2708.meta
|   |   |   |       |-- subdir7
|   |   |   |       |   |-- blk_1073743809
|   |   |   |       |   |-- blk_1073743809_2985.meta
|   |   |   |       |   |-- blk_1073743810
|   |   |   |       |   |-- blk_1073743810_2986.meta
|   |   |   |       |   |-- blk_1073743813
|   |   |   |       |   |-- blk_1073743813_2989.meta
|   |   |   |       |   |-- blk_1073743814
|   |   |   |       |   |-- blk_1073743814_2990.meta
|   |   |   |       |   |-- blk_1073743845
|   |   |   |       |   |-- blk_1073743845_3021.meta
|   |   |   |       |   |-- blk_1073743847
|   |   |   |       |   |-- blk_1073743847_3023.meta
|   |   |   |       |   |-- blk_1073743848
|   |   |   |       |   |-- blk_1073743848_3024.meta
|   |   |   |       |   |-- blk_1073743849
|   |   |   |       |   |-- blk_1073743849_3025.meta
|   |   |   |       |   |-- blk_1073743850
|   |   |   |       |   |-- blk_1073743850_3026.meta
|   |   |   |       |   |-- blk_1073743851
|   |   |   |       |   |-- blk_1073743851_3027.meta
|   |   |   |       |   |-- blk_1073743852
|   |   |   |       |   |-- blk_1073743852_3028.meta
|   |   |   |       |   |-- blk_1073743866
|   |   |   |       |   `-- blk_1073743866_3042.meta
|   |   |   |       `-- subdir8
|   |   |   |-- rbw
|   |   |   `-- VERSION
|   |   |-- scanner.cursor
|   |   `-- tmp
|   `-- VERSION
`-- in_use.lock

16 directories, 179 files

--hdfs為操作HDFS的工具程式  
[cloudera@cdh6 ~]$ which hdfs
/usr/bin/hdfs  --hadoop client(hdfs)程式,至少安裝hadoop client
  
[cloudera@cdh6 ~]$ which yarn
/usr/bin/yarn  --hadoop client(YARN)程式,至少安裝hadoop client
  
[cloudera@cdh6 ~]$ hdfs
Usage: hdfs [--config confdir] COMMAND
       where COMMAND is one of:
  dfs                  run a filesystem command on the file systems supported in Hadoop.
  namenode -format     format the DFS filesystem
  secondarynamenode    run the DFS secondary namenode
  namenode             run the DFS namenode
  journalnode          run the DFS journalnode
  zkfc                 run the ZK Failover Controller daemon
  datanode             run a DFS datanode
  dfsadmin             run a DFS admin client
  diskbalancer         Distributes data evenly among disks on a given node
  haadmin              run a DFS HA admin client
  fsck                 run a DFS filesystem checking utility
  balancer             run a cluster balancing utility
  jmxget               get JMX exported values from NameNode or DataNode.
  mover                run a utility to move block replicas across
                       storage types
  oiv                  apply the offline fsimage viewer to an fsimage
  oiv_legacy           apply the offline fsimage viewer to an legacy fsimage
  oev                  apply the offline edits viewer to an edits file
  fetchdt              fetch a delegation token from the NameNode
  getconf              get config values from configuration
  groups               get the groups which users belong to
  snapshotDiff         diff two snapshots of a directory or diff the
                       current directory contents with a snapshot
  lsSnapshottableDir   list all snapshottable dirs owned by the current user
                                                Use -help to see options
  portmap              run a portmap service
  nfs3                 run an NFS version 3 gateway
  cacheadmin           configure the HDFS cache
  crypto               configure HDFS encryption zones
  storagepolicies      list/get/set block storage policies
  version              print the version

Most commands print help when invoked w/o parameters.

[cloudera@cdh6 ~]$ hdfs dfs
Usage: hadoop fs [generic options]
        [-appendToFile <localsrc> ... <dst>]
        [-cat [-ignoreCrc] <src> ...]
        [-checksum <src> ...]
        [-chgrp [-R] GROUP PATH...]
        [-chmod [-R] <MODE[,MODE]... | OCTALMODE> PATH...]
        [-chown [-R] [OWNER][:[GROUP]] PATH...]
        [-copyFromLocal [-f] [-p] [-l] <localsrc> ... <dst>]
        [-copyToLocal [-p] [-ignoreCrc] [-crc] <src> ... <localdst>]
        [-count [-q] [-h] [-v] [-x] <path> ...]
        [-cp [-f] [-p | -p[topax]] <src> ... <dst>]
        [-createSnapshot <snapshotDir> [<snapshotName>]]
        [-deleteSnapshot <snapshotDir> <snapshotName>]
        [-df [-h] [<path> ...]]
        [-du [-s] [-h] [-x] <path> ...]
        [-expunge]
        [-find <path> ... <expression> ...]
        [-get [-p] [-ignoreCrc] [-crc] <src> ... <localdst>]
        [-getfacl [-R] <path>]
        [-getfattr [-R] {-n name | -d} [-e en] <path>]
        [-getmerge [-nl] <src> <localdst>]
        [-help [cmd ...]]
        [-ls [-C] [-d] [-h] [-q] [-R] [-t] [-S] [-r] [-u] [<path> ...]]
        [-mkdir [-p] <path> ...]
        [-moveFromLocal <localsrc> ... <dst>]
        [-moveToLocal <src> <localdst>]
        [-mv <src> ... <dst>]
        [-put [-f] [-p] [-l] <localsrc> ... <dst>]
        [-renameSnapshot <snapshotDir> <oldName> <newName>]
        [-rm [-f] [-r|-R] [-skipTrash] <src> ...]
        [-rmdir [--ignore-fail-on-non-empty] <dir> ...]
        [-setfacl [-R] [{-b|-k} {-m|-x <acl_spec>} <path>]|[--set <acl_spec> <path>]]
        [-setfattr {-n name [-v value] | -x name} <path>]
        [-setrep [-R] [-w] <rep> <path> ...]
        [-stat [format] <path> ...]
        [-tail [-f] <file>]
        [-test -[defsz] <path>]
        [-text [-ignoreCrc] <src> ...]
        [-touchz <path> ...]
        [-usage [cmd ...]]

Generic options supported are
-conf <configuration file>     specify an application configuration file
-D <property=value>            use value for given property
-fs <local|namenode:port>      specify a namenode
-jt <local|resourcemanager:port>    specify a ResourceManager
-files <comma separated list of files>    specify comma separated files to be copied to the map reduce cluster
-libjars <comma separated list of jars>    specify comma separated jar files to include in the classpath.
-archives <comma separated list of archives>    specify comma separated archives to be unarchived on the compute machines.

The general command line syntax is
bin/hadoop command [genericOptions] [commandOptions]
  
--HDFS沒有內建使用者,一切仰賴OS所提供的使用者資訊

                                      如果沒有提供hdfs目錄,將自動使用home directory
                                      --------------
[cloudera@cdh6 ~]$ hdfs dfs -ls 
                      -- hdfs dfs -ls /user/cloudera
					                        --------
											執行hdfs工具的os username
--HDFS 根目錄 /
[cloudera@cdh6 ~]$ hdfs dfs -ls /
Found 6 items
drwxrwxrwx   - hdfs  supergroup          0 2017-10-23 09:15 /benchmarks
drwxr-xr-x   - hbase supergroup          0 2019-06-23 20:42 /hbase
drwxr-xr-x   - solr  solr                0 2017-10-23 09:18 /solr
drwxrwxrwt   - hdfs  supergroup          0 2019-06-23 20:42 /tmp
drwxr-xr-x   - hdfs  supergroup          0 2017-10-23 09:17 /user
drwxr-xr-x   - hdfs  supergroup          0 2017-10-23 09:17 /var

[cloudera@cdh6 ~]$ hdfs dfs -ls /user/
Found 8 items
drwxr-xr-x   - cloudera cloudera            0 2017-10-23 09:14 /user/cloudera
drwxr-xr-x   - mapred   hadoop              0 2019-06-23 20:41 /user/history
drwxrwxrwx   - hive     supergroup          0 2017-10-23 09:17 /user/hive
drwxrwxrwx   - hue      supergroup          0 2019-06-23 20:47 /user/hue
drwxrwxrwx   - jenkins  supergroup          0 2017-10-23 09:15 /user/jenkins
drwxrwxrwx   - oozie    supergroup          0 2017-10-23 09:16 /user/oozie
drwxrwxrwx   - root     supergroup          0 2017-10-23 09:16 /user/root
drwxr-xr-x   - hdfs     supergroup          0 2017-10-23 09:17 /user/spark

--os user(cloudera)的家目錄/user/cloudera
[cloudera@cdh6 ~]$ hdfs dfs -ls /user/cloudera
Found 6 items
drwx------   - cloudera cloudera          0 2019-09-22 23:00 /user/cloudera/.Trash
drwxr-xr-x   - cloudera cloudera          0 2019-06-28 01:20 /user/cloudera/.sparkStaging
drwx------   - cloudera cloudera          0 2019-06-27 19:01 /user/cloudera/.staging
-rw-r--r--   1 cloudera cloudera         80 2019-06-26 22:30 /user/cloudera/dept1.csv
-rw-r--r--   1 cloudera cloudera        650 2019-06-26 08:34 /user/cloudera/emp.csv
-rw-r--r--   1 cloudera cloudera        617 2019-06-26 19:38 /user/cloudera/emp1.csv


--首先從10.0.1.100:5050下載shakespeare.txt
[cloudera@cdh6 ~]$ curl -O http://10.0.1.100:5050/Class_Log/shakespeare.txt
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
100 5316k  100 5316k    0     0  30.3M      0 --:--:-- --:--:-- --:--:-- 31.0M

--上傳本地端檔案到HDFS 
--$ hdfs dfs -put localfile remotefile
[cloudera@cdh6 ~]$ ls -l shakespeare.txt
-rw-rw-r-- 1 cloudera cloudera 5444257 Sep 23 00:16 shakespeare.txt
                                                                      ----------如果不指定hdfs端目錄,則使用家目錄
[cloudera@cdh6 ~]$ hdfs dfs -put /home/cloudera/shakespeare.txt 
                      -- hdfs dfs -put /home/cloudera/shakespeare.txt  /user/cloudera/shakespeare.txt 
					  
					  -- hdfs dfs -ls /user/cloudera
[cloudera@cdh6 ~]$ hdfs dfs -ls /user/cloudera
Found 7 items
drwx------   - cloudera cloudera          0 2019-09-22 23:00 /user/cloudera/.Trash
drwxr-xr-x   - cloudera cloudera          0 2019-06-28 01:20 /user/cloudera/.sparkStaging
drwx------   - cloudera cloudera          0 2019-06-27 19:01 /user/cloudera/.staging
-rw-r--r--   1 cloudera cloudera         80 2019-06-26 22:30 /user/cloudera/dept1.csv
-rw-r--r--   1 cloudera cloudera        650 2019-06-26 08:34 /user/cloudera/emp.csv
-rw-r--r--   1 cloudera cloudera        617 2019-06-26 19:38 /user/cloudera/emp1.csv
-rw-r--r--   1 cloudera cloudera    5444257 2019-09-23 00:18 /user/cloudera/shakespeare.txt

--顯示/user/cloudera/shakespeare.txt由那些hdfs區塊組成
--請使用Cloudera Manager -> HDFS -> NameNode WebUI
--NameNode WebUI http://cdh6:9870/     -> Hadoop 3 (Hadoop 2的NameNode使用port:50070)
  --Utilities -> browse the filesystem -> 選擇shakespeare.txt

[cloudera@cdh6 ~]$ hdfs fsck -blocks -files /user/cloudera/shakespeare.txt
Connecting to namenode via http://cdh6:9870/fsck?ugi=cloudera&blocks=1&files=1&path=%2Fuser%2Fcloudera%2Fshakespeare.txt
FSCK started by cloudera (auth:SIMPLE) from /10.0.2.15 for path /user/cloudera/shakespeare.txt at Sat Mar 21 01:38:25 PDT 2020
/user/cloudera/shakespeare.txt 5444257 bytes, 1 block(s):  OK
0. BP-1067413441-127.0.0.1-1508775264580:blk_1073747183_6376 len=5444257 Live_repl=1

Status: HEALTHY
 Total size:    5444257 B
 Total dirs:    0
 Total files:   1
 Total symlinks:                0
 Total blocks (validated):      1 (avg. block size 5444257 B)
 Minimally replicated blocks:   1 (100.0 %)
 Over-replicated blocks:        0 (0.0 %)
 Under-replicated blocks:       0 (0.0 %)
 Mis-replicated blocks:         0 (0.0 %)
 Default replication factor:    1
 Average block replication:     1.0
 Corrupt blocks:                0
 Missing replicas:              0 (0.0 %)
 Number of data-nodes:          1
 Number of racks:               1
FSCK ended at Sat Mar 21 01:38:25 PDT 2020 in 1 milliseconds


The filesystem under path '/user/cloudera/shakespeare.txt' is HEALTHY


--下載HDFS檔案到本地端
[cloudera@cdh6 ~]$ ls -l shakespeare.txt
-rw-rw-r-- 1 cloudera cloudera 5444257 Sep 23 00:16 shakespeare.txt
[cloudera@cdh6 ~]$ rm shakespeare.txt
rm: remove regular file `shakespeare.txt'? y
[cloudera@cdh6 ~]$ ls -l shakespeare.txt
ls: cannot access shakespeare.txt: No such file or directory
[cloudera@cdh6 ~]$ hdfs dfs -get /user/cloudera/shakespeare.txt
[cloudera@cdh6 ~]$ ls -l shakespeare.txt
-rw-r--r-- 1 cloudera cloudera 5444257 Sep 23 00:26 shakespeare.txt

--檢視HDFS Block對應本機檔案系統的位置
1. http://cdh6:9870/   -> utilities -> browse the file system


                          -----------------------------------------
[cloudera@cdh6 ~]$ ls -l /var/lib/hadoop-hdfs/cache/hdfs/dfs/data/
total 8
drwxr-xr-x 3 hdfs hadoop 4096 Oct 23  2017 current
-rw-r--r-- 1 hdfs hdfs     24 Jun 23 20:40 in_use.lock
[cloudera@cdh6 ~]$ ls -l /var/lib/hadoop-hdfs/cache/hdfs/dfs/data/current/BP-1067413441-127.0.0.1-1508775264580/current/finalized/subdir0/subdir19/blk_1073746829
-rw-r--r-- 1 hdfs hdfs 5444257 Sep 23 00:18 /var/lib/hadoop-hdfs/cache/hdfs/dfs/data/current/BP-1067413441-127.0.0.1-1508775264580/current/finalized/subdir0/subdir19/blk_1073746829
[cloudera@cdh6 ~]$ tail /var/lib/hadoop-hdfs/cache/hdfs/dfs/data/current/BP-1067413441-127.0.0.1-1508775264580/current/finalized/subdir0/subdir19/blk_1073746829

  'O, that infected moisture of his eye,
  O, that false fire which in his cheek so glowed,
  O, that forced thunder from his heart did fly,
  O, that sad breath his spongy lungs bestowed,
  O, all that borrowed motion, seeming owed,
  Would yet again betray the fore-betrayed,
  And new pervert a reconciled maid.'

THE END


--由客戶端明確指定HDFS區塊大小(-D dfs.block.size=1M)
[cloudera@cdh6 ~]$ hdfs dfs -D dfs.block.size=1M -put /home/cloudera/shakespeare.txt /user/cloudera/shakespeare_1M.txt

[cloudera@cdh6 ~]$ hdfs dfs -ls
Found 8 items
drwx------   - cloudera cloudera          0 2019-09-22 23:00 .Trash
drwxr-xr-x   - cloudera cloudera          0 2019-06-28 01:20 .sparkStaging
drwx------   - cloudera cloudera          0 2019-06-27 19:01 .staging
-rw-r--r--   1 cloudera cloudera         80 2019-06-26 22:30 dept1.csv
-rw-r--r--   1 cloudera cloudera        650 2019-06-26 08:34 emp.csv
-rw-r--r--   1 cloudera cloudera        617 2019-06-26 19:38 emp1.csv
-rw-r--r--   1 cloudera cloudera    5444257 2019-09-23 00:18 shakespeare.txt
-rw-r--r--   1 cloudera cloudera    5444257 2019-09-23 00:28 shakespeare_1M.txt

--顯示HDFS檔案的區塊數量
[cloudera@cdh6 ~]$ hdfs fsck /user/cloudera/shakespeare.txt -files -blocks
Connecting to namenode via http://cdh6:9870/fsck?ugi=cloudera&files=1&blocks=1&path=%2Fuser%2Fcloudera%2Fshakespeare.txt
FSCK started by cloudera (auth:SIMPLE) from /127.0.0.1 for path /user/cloudera/shakespeare.txt at Mon Sep 23 00:29:39 PDT 2019
/user/cloudera/shakespeare.txt 5444257 bytes, 1 block(s):  OK
0. BP-1067413441-127.0.0.1-1508775264580:blk_1073746829_6022 len=5444257 Live_repl=1

Status: HEALTHY
 Total size:    5444257 B
 Total dirs:    0
 Total files:   1
 Total symlinks:                0
 Total blocks (validated):      1 (avg. block size 5444257 B)
 Minimally replicated blocks:   1 (100.0 %)
 Over-replicated blocks:        0 (0.0 %)
 Under-replicated blocks:       0 (0.0 %)
 Mis-replicated blocks:         0 (0.0 %)
 Default replication factor:    1
 Average block replication:     1.0
 Corrupt blocks:                0
 Missing replicas:              0 (0.0 %)
 Number of data-nodes:          1
 Number of racks:               1
FSCK ended at Mon Sep 23 00:29:39 PDT 2019 in 1 milliseconds


The filesystem under path '/user/cloudera/shakespeare.txt' is HEALTHY
[cloudera@cdh6 ~]$ hdfs dfs -D dfs.block.size=1M -put /home/cloudera/shakespeare.txt /user/cloudera/shakespeare_1M.txt
[cloudera@cdh6 ~]$ hdfs fsck -blocks -files /user/cloudera/shakespeare_1M.txt                                      Connecting to namenode via http://cdh6:9870/fsck?ugi=cloudera&blocks=1&files=1&path=%2Fuser%2Fcloudera%2Fshakespeare_1M.txt
FSCK started by cloudera (auth:SIMPLE) from /192.168.56.103 for path /user/cloudera/shakespeare_1M.txt at Mon Sep 14 14:15:14 CST 2020
/user/cloudera/shakespeare_1M.txt 5436535 bytes, replicated: replication=1, 6 block(s):  OK
0. BP-343982396-192.168.56.103-1599099880694:blk_1073743847_3023 len=1048576 Live_repl=1
1. BP-343982396-192.168.56.103-1599099880694:blk_1073743848_3024 len=1048576 Live_repl=1
2. BP-343982396-192.168.56.103-1599099880694:blk_1073743849_3025 len=1048576 Live_repl=1
3. BP-343982396-192.168.56.103-1599099880694:blk_1073743850_3026 len=1048576 Live_repl=1
4. BP-343982396-192.168.56.103-1599099880694:blk_1073743851_3027 len=1048576 Live_repl=1
5. BP-343982396-192.168.56.103-1599099880694:blk_1073743852_3028 len=193655 Live_repl=1


Status: HEALTHY
 Number of data-nodes:  1
 Number of racks:               1
 Total dirs:                    0
 Total symlinks:                0

Replicated Blocks:
 Total size:    5436535 B
 Total files:   1
 Total blocks (validated):      6 (avg. block size 906089 B)
 Minimally replicated blocks:   6 (100.0 %)
 Over-replicated blocks:        0 (0.0 %)
 Under-replicated blocks:       0 (0.0 %)
 Mis-replicated blocks:         0 (0.0 %)
 Default replication factor:    1
 Average block replication:     1.0
 Missing blocks:                0
 Corrupt blocks:                0
 Missing replicas:              0 (0.0 %)
 Blocks queued for replication: 0

Erasure Coded Block Groups:
 Total size:    0 B
 Total files:   0
 Total block groups (validated):        0
 Minimally erasure-coded block groups:  0
 Over-erasure-coded block groups:       0
 Under-erasure-coded block groups:      0
 Unsatisfactory placement block groups: 0
 Average block group size:      0.0
 Missing block groups:          0
 Corrupt block groups:          0
 Missing internal blocks:       0
 Blocks queued for replication: 0
FSCK ended at Mon Sep 14 14:15:14 CST 2020 in 1 milliseconds


The filesystem under path '/user/cloudera/shakespeare_1M.txt' is HEALTHY

--建立一個HDFS目錄
[cloudera@cdh6 ~]$ hdfs dfs -mkdir testdir
                                 --/user/cloudera/testdir
--上傳pg1778.txt到HDFS
[cloudera@cdh6 ~]$ hdfs fsck -blocks -files /user/cloudera/testdir/pg1778.txt
Connecting to namenode via http://cdh6:9870/fsck?ugi=cloudera&blocks=1&files=1&path=%2Fuser%2Fcloudera%2Ftestdir%2Fpg1778.txt
FSCK started by cloudera (auth:SIMPLE) from /192.168.56.103 for path /user/cloudera/testdir/pg1778.txt at Mon Sep 14 14:30:14 CST 2020
/user/cloudera/testdir/pg1778.txt 121627 bytes, replicated: replication=1, 1 block(s):  OK
0. BP-343982396-192.168.56.103-1599099880694:blk_1073743866_3042 len=121627 Live_repl=1

--移動檔案(更名或換位置),mv僅針對Namenode's metadata並不會導致Datanode的操作
[cloudera@cdh6 ~]$ hdfs dfs -mv pg1778.txt summer_night.txt
[cloudera@cdh6 ~]$ hdfs dfs -ls
Found 2 items
-rw-r--r--   1 cloudera cloudera     121627 2019-06-23 22:38 summer_night.txt
drwxr-xr-x   - cloudera cloudera          0 2019-06-23 23:57 testdir
[cloudera@cdh6 ~]$ hdfs fsck -blocks -files /user/cloudera/summer_night.txt
Connecting to namenode via http://cdh6:9870/fsck?ugi=cloudera&blocks=1&files=1&path=%2Fuser%2Fcloudera%2Fsummer_night.txt
FSCK started by cloudera (auth:SIMPLE) from /192.168.56.103 for path /user/cloudera/summer_night.txt at Mon Sep 14 14:32:25 CST 2020
/user/cloudera/summer_night.txt 121627 bytes, replicated: replication=1, 1 block(s):  OK
0. BP-343982396-192.168.56.103-1599099880694:blk_1073743866_3042 len=121627 Live_repl=1

[cloudera@cdh6 ~]$ hdfs dfs -mv testdir/pg1778.txt summer_night.txt
[cloudera@cdh6 ~]$ hdfs dfs -ls
Found 9 items
drwx------   - cloudera supergroup          0 2020-09-14 10:00 .Trash
drwxr-xr-x   - cloudera supergroup          0 2020-09-08 21:07 .sparkStaging
drwx------   - cloudera supergroup          0 2020-09-08 17:13 .staging
-rw-r--r--   1 cloudera supergroup        617 2020-09-08 15:09 emp1.csv
-rw-r--r--   1 cloudera supergroup    5436535 2020-09-14 14:14 shakespeare.txt
-rw-r--r--   1 cloudera supergroup    5436535 2020-09-14 14:15 shakespeare_1M.txt
-rw-r--r--   1 cloudera supergroup  227893062 2020-09-14 13:42 spark-2.4.0-bin-hadoop2.7.tgz
-rw-r--r--   1 cloudera supergroup     121627 2020-09-14 14:28 summer_night.txt
drwxr-xr-x   - cloudera supergroup          0 2020-09-14 14:31 testdir

--/user/cloudera/summer_night.txt所在HDFS為事先設定在/etc/hadoop/conf/core-site.xml
[cloudera@cdh6 ~]$ hdfs dfs -ls /user/cloudera/summer_night.txt
-rw-r--r--   1 cloudera cloudera     121627 2019-06-23 22:38 /user/cloudera/summer_night.txt
                                                        
														RPC port
                                                        ----
[cloudera@cdh6 ~]$ hdfs dfs -ls hdfs://cdh6:8020/user/cloudera/summer_night.txt
-rw-r--r--   1 cloudera cloudera     121627 2019-06-23 22:38 hdfs://cdh6:8020/user/cloudera/summer_night.txt

hdfs dfs -cp hdfsfile1 hdfsfile2
hdfs dfs -rm hdfsfile1
hdfs dfs -rm -r hdfsdir

[cloudera@cdh6 ~]$ rm shakespeare.txt
[cloudera@cdh6 ~]$ ls shakespeare.txt
ls: cannot access shakespeare.txt: No such file or directory

--使用-get將HDFS file下載至local filesystem
[cloudera@cdh6 ~]$ hdfs dfs -get /user/cloudera/shakespeare.txt
[cloudera@cdh6 ~]$ ls shakespeare.txt
shakespeare.txt
	
--hdfs dfs -getmerge hdfsdir 
	
[cloudera@cdh6 ~]$ hdfs dfs -ls /
Found 6 items
drwxrwxrwx   - hdfs  supergroup          0 2017-10-23 09:15 /benchmarks
drwxr-xr-x   - hbase supergroup          0 2019-06-23 20:42 /hbase
drwxr-xr-x   - solr  solr                0 2017-10-23 09:18 /solr
drwxrwxrwt   - hdfs  supergroup          0 2019-06-23 20:42 /tmp
drwxr-xr-x   - hdfs  supergroup          0 2017-10-23 09:17 /user
drwxr-xr-x   - hdfs  supergroup          0 2017-10-23 09:17 /var

--namenode的web ui port: 50070  --CDH5
--namenode的web ui port: 9870   --CDH6
[cloudera@cdh6 ~]$ hdfs fsck /
Connecting to namenode via http://cdh6:9870/fsck?ugi=cloudera&path=%2F
FSCK started by cloudera (auth:SIMPLE) from /192.168.56.103 for path / at Mon Sep 14 14:38:36 CST 2020
FSCK ended at Mon Sep 14 14:38:36 CST 2020 in 2 milliseconds
Permission denied: user=cloudera, access=READ_EXECUTE, inode="/tmp/.cloudera_health_monitoring_canary_files":hdfs:supergroup:d---------


Fsck on path '/' FAILED --cloudera的權限不足
  
[cloudera@cdh6 ~]$ cat /etc/passwd
root:x:0:0:root:/root:/bin/bash
bin:x:1:1:bin:/bin:/sbin/nologin
daemon:x:2:2:daemon:/sbin:/sbin/nologin
adm:x:3:4:adm:/var/adm:/sbin/nologin
lp:x:4:7:lp:/var/spool/lpd:/sbin/nologin
sync:x:5:0:sync:/sbin:/bin/sync
shutdown:x:6:0:shutdown:/sbin:/sbin/shutdown
halt:x:7:0:halt:/sbin:/sbin/halt
mail:x:8:12:mail:/var/spool/mail:/sbin/nologin
uucp:x:10:14:uucp:/var/spool/uucp:/sbin/nologin
operator:x:11:0:operator:/root:/sbin/nologin
games:x:12:100:games:/usr/games:/sbin/nologin
gopher:x:13:30:gopher:/var/gopher:/sbin/nologin
ftp:x:14:50:FTP User:/var/ftp:/sbin/nologin
nobody:x:99:99:Nobody:/:/sbin/nologin
dbus:x:81:81:System message bus:/:/sbin/nologin
vcsa:x:69:69:virtual console memory owner:/dev:/sbin/nologin
abrt:x:173:173::/etc/abrt:/sbin/nologin
haldaemon:x:68:68:HAL daemon:/:/sbin/nologin
ntp:x:38:38::/etc/ntp:/sbin/nologin
saslauth:x:499:76:Saslauthd user:/var/empty/saslauth:/sbin/nologin
postfix:x:89:89::/var/spool/postfix:/sbin/nologin
sshd:x:74:74:Privilege-separated SSH:/var/empty/sshd:/sbin/nologin
tcpdump:x:72:72::/:/sbin/nologin
zookeeper:x:498:499:ZooKeeper:/var/lib/zookeeper:/sbin/nologin
cloudera-scm:x:497:498:Cloudera Manager:/var/lib/cloudera-scm-server:/sbin/nologin
rpc:x:32:32:Rpcbind Daemon:/var/cache/rpcbind:/sbin/nologin
apache:x:48:48:Apache:/var/www:/sbin/nologin
solr:x:496:496:Solr:/var/lib/solr:/sbin/nologin
hbase:x:495:495:HBase:/var/lib/hbase:/sbin/nologin
sentry:x:494:494:Sentry:/var/lib/sentry:/sbin/nologin
hive:x:493:493:Hive:/var/lib/hive:/sbin/nologin
hdfs:x:492:491:Hadoop HDFS:/var/lib/hadoop-hdfs:/bin/bash                               --HDFS最高權限的使用者
yarn:x:491:490:Hadoop Yarn:/var/lib/hadoop-yarn:/bin/bash                               --YARN最高權限的使用者
impala:x:490:489:Impala:/var/lib/impala:/bin/bash
mapred:x:489:488:Hadoop MapReduce:/var/lib/hadoop-mapreduce:/bin/bash
hue:x:488:487:Hue:/usr/lib/hue:/sbin/nologin
sqoop:x:487:486:Sqoop:/var/lib/sqoop:/sbin/nologin
flume:x:486:485:Flume:/var/lib/flume-ng:/sbin/nologin
spark:x:485:484:Spark:/var/lib/spark:/sbin/nologin
sqoop2:x:484:486:Sqoop 2 User:/var/lib/sqoop2:/sbin/nologin
oozie:x:483:483:Oozie User:/var/lib/oozie:/bin/false
mysql:x:27:27:MySQL Server:/var/lib/mysql:/bin/bash
kms:x:482:482:Hadoop KMS:/var/lib/hadoop-kms:/bin/bash
llama:x:500:481:Llama:/var/lib/llama:/bin/bash
httpfs:x:481:480:Hadoop HTTPFS:/var/lib/hadoop-httpfs:/bin/bash
gdm:x:42:42::/var/lib/gdm:/sbin/nologin
rtkit:x:480:477:RealtimeKit:/proc:/sbin/nologin
pulse:x:479:476:PulseAudio System Daemon:/var/run/pulse:/sbin/nologin
avahi-autoipd:x:170:170:Avahi IPv4LL Stack:/var/lib/avahi-autoipd:/sbin/nologin
cloudera:x:501:501::/home/cloudera:/bin/bash
vboxadd:x:478:1::/var/run/vboxadd:/bin/false

                         切換為hdfs使用者
                         --------------
[cloudera@cdh6 ~]$ sudo su - hdfs hdfs fsck /
Connecting to namenode via http://cdh6:9870/fsck?ugi=hdfs&path=%2F
FSCK started by hdfs (auth:SIMPLE) from /127.0.0.1 for path / at Mon Jun 24 00:10:30 PDT 2019
....................................................................................................
....................................................................................................
....................................................................................................
....................................................................................................
....................................................................................................
....................................................................................................
....................................................................................................
....................................................................................................
....................................................................................................
...................................Status: HEALTHY
 Total size:	868801325 B (Total open files size: 166 B)
 Total dirs:	355
 Total files:	935
 Total symlinks:		0 (Files currently being written: 3)
 Total blocks (validated):	936 (avg. block size 928206 B) (Total open file blocks (not validated): 2)
 Minimally replicated blocks:	936 (100.0 %)
 Over-replicated blocks:	0 (0.0 %)
 Under-replicated blocks:	0 (0.0 %)
 Mis-replicated blocks:		0 (0.0 %)
 Default replication factor:	1
 Average block replication:	1.0
 Corrupt blocks:		0
 Missing replicas:		0 (0.0 %)
 Number of data-nodes:		1
 Number of racks:		1
FSCK ended at Mon Jun 24 00:10:31 PDT 2019 in 366 milliseconds


The filesystem under path '/' is HEALTHY

--BlockScannerReport
http://quickstart:50075/blockScannerReport  --CDH5
http://cdh6:9864/blockScannerReport         --CDH6

[cloudera@cdh6 ~]$ hdfs dfs -ls
Found 9 items
drwx------   - cloudera supergroup          0 2020-09-14 10:00 .Trash
drwxr-xr-x   - cloudera supergroup          0 2020-09-08 21:07 .sparkStaging
drwx------   - cloudera supergroup          0 2020-09-08 17:13 .staging
-rw-r--r--   1 cloudera supergroup        617 2020-09-08 15:09 emp1.csv
-rw-r--r--   1 cloudera supergroup    5436535 2020-09-14 14:14 shakespeare.txt
-rw-r--r--   1 cloudera supergroup    5436535 2020-09-14 14:15 shakespeare_1M.txt
-rw-r--r--   1 cloudera supergroup  227893062 2020-09-14 13:42 spark-2.4.0-bin-hadoop2.7.tgz
-rw-r--r--   1 cloudera supergroup     121627 2020-09-14 14:28 summer_night.txt
drwxr-xr-x   - cloudera supergroup          0 2020-09-14 14:31 testdir

--從HDFS將HDFS file內容顯示在hdfs工具的客戶端
[cloudera@cdh6 ~]$ hdfs dfs -cat emp1.csv
7839,KING,PRESIDENT,,17-NOV-81,5000,,10
7698,BLAKE,MANAGER,7839,01-MAY-81,2850,,30
7782,CLARK,MANAGER,7839,09-JUN-81,2450,,10
7566,JONES,MANAGER,7839,02-APR-81,2975,,20
7788,SCOTT,ANALYST,7566,19-APR-87,3000,,20
7902,FORD,ANALYST,7566,03-DEC-81,3000,,20
7369,SMITH,CLERK,7902,17-DEC-80,800,,20
7499,ALLEN,SALESMAN,7698,20-FEB-81,1600,300,30
7521,WARD,SALESMAN,7698,22-FEB-81,1250,500,30
7654,MARTIN,SALESMAN,7698,28-SEP-81,1250,1400,30
7844,TURNER,SALESMAN,7698,08-SEP-81,1500,0,30
7876,ADAMS,CLERK,7788,23-MAY-87,1100,,20
7900,JAMES,CLERK,7698,03-DEC-81,950,,30
7934,MILLER,CLERK,7782,23-JAN-82,1300,,10

[cloudera@cdh6 ~]$ hdfs dfs -cat emp1.csv > emp1.csv
[cloudera@cdh6 ~]$ ls -l /home/cloudera/emp1.csv
-rwx------ 1 cloudera cloudera 617 Sep 14 15:54 /home/cloudera/emp1.csv
[cloudera@cdh6 ~]$ cat /home/cloudera/emp1.csv
7839,KING,PRESIDENT,,17-NOV-81,5000,,10
7698,BLAKE,MANAGER,7839,01-MAY-81,2850,,30
7782,CLARK,MANAGER,7839,09-JUN-81,2450,,10
7566,JONES,MANAGER,7839,02-APR-81,2975,,20
7788,SCOTT,ANALYST,7566,19-APR-87,3000,,20
7902,FORD,ANALYST,7566,03-DEC-81,3000,,20
7369,SMITH,CLERK,7902,17-DEC-80,800,,20
7499,ALLEN,SALESMAN,7698,20-FEB-81,1600,300,30
7521,WARD,SALESMAN,7698,22-FEB-81,1250,500,30
7654,MARTIN,SALESMAN,7698,28-SEP-81,1250,1400,30
7844,TURNER,SALESMAN,7698,08-SEP-81,1500,0,30
7876,ADAMS,CLERK,7788,23-MAY-87,1100,,20
7900,JAMES,CLERK,7698,03-DEC-81,950,,30
7934,MILLER,CLERK,7782,23-JAN-82,1300,,10

[cloudera@cdh6 ~]$ hdfs dfs -get /user/cloudera/emp1.csv emp.csv
get: `emp.csv': File exists
[cloudera@cdh6 ~]$ hdfs dfs -get /user/cloudera/emp1.csv emp2.csv

[cloudera@cdh6 ~]$ hdfs dfs -ls /user/cloudera/emp1.csv
-rw-r--r--   1 cloudera supergroup        617 2020-09-08 15:09 /user/cloudera/emp1.csv

--根據CDH設定,HDFS file可能立刻被刪除或者先暫時移至.Trash目錄,之後才被刪除
[cloudera@cdh6 ~]$ hdfs dfs -rm /user/cloudera/emp1.csv
20/09/14 15:56:19 INFO fs.TrashPolicyDefault: Moved: 'hdfs://cdh6:8020/user/cloudera/emp1.csv' to trash at: hdfs://cdh6:8020/user/cloudera/.Trash/Current/user/cloudera/emp1.csv

[cloudera@cdh6 ~]$ hdfs dfs -ls /user/cloudera/emp1.csv
ls: `/user/cloudera/emp1.csv': No such file or directory
[cloudera@cdh6 ~]$ hdfs dfs -ls /user/cloudera
Found 8 items
drwx------   - cloudera supergroup          0 2020-09-14 15:56 /user/cloudera/.Trash
drwxr-xr-x   - cloudera supergroup          0 2020-09-08 21:07 /user/cloudera/.sparkStaging
drwx------   - cloudera supergroup          0 2020-09-08 17:13 /user/cloudera/.staging
-rw-r--r--   1 cloudera supergroup    5436535 2020-09-14 14:14 /user/cloudera/shakespeare.txt
-rw-r--r--   1 cloudera supergroup    5436535 2020-09-14 14:15 /user/cloudera/shakespeare_1M.txt
-rw-r--r--   1 cloudera supergroup  227893062 2020-09-14 13:42 /user/cloudera/spark-2.4.0-bin-hadoop2.7.tgz
-rw-r--r--   1 cloudera supergroup     121627 2020-09-14 14:28 /user/cloudera/summer_night.txt
drwxr-xr-x   - cloudera supergroup          0 2020-09-14 14:31 /user/cloudera/testdir
[cloudera@cdh6 ~]$ hdfs dfs -ls /user/cloudera/.Trash/
Found 1 items
drwx------   - cloudera supergroup          0 2020-09-14 15:56 /user/cloudera/.Trash/Current
[cloudera@cdh6 ~]$ hdfs dfs -ls /user/cloudera/.Trash/Current
Found 1 items
drwx------   - cloudera supergroup          0 2020-09-14 15:56 /user/cloudera/.Trash/Current/user
[cloudera@cdh6 ~]$ hdfs dfs -ls /user/cloudera/.Trash/Current/user
Found 1 items
drwx------   - cloudera supergroup          0 2020-09-14 15:56 /user/cloudera/.Trash/Current/user/cloudera
[cloudera@cdh6 ~]$ hdfs dfs -ls /user/cloudera/.Trash/Current/user/cloudera/
Found 1 items
-rw-r--r--   1 cloudera supergroup        617 2020-09-08 15:09 /user/cloudera/.Trash/Current/user/cloudera/emp1.csv
[cloudera@cdh6 ~]$ hdfs dfs -mv /user/cloudera/.Trash/Current/user/cloudera/emp1.csv /user/cloudera/emp1.csv

--目前hdfs工具連線到哪個Hadoop cluster?(每個Hadoop Cluster只需要一組(active/standby)NameNode
[cloudera@cdh6 ~]$ hdfs dfs -ls /user/cloudera/emp1.csv
-rw-r--r--   1 cloudera supergroup        617 2020-09-08 15:09 /user/cloudera/emp1.csv

[cloudera@cdh6 ~]$ cat /etc/hadoop/conf/core-site.xml | grep defaultFS -B 1 -A 2
  <property>
    <name>fs.defaultFS</name>
    <value>hdfs://cdh6:8020</value>
  </property>

hdfs dfs -ls /user/cloudera/emp1.csv 等同於 hdfs dfs -ls hdfs://cdh6:8020/user/cloudera/emp1.csv

\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\
--Apache Flume
--/etc/flume-ng/conf/

--flume agent:tail1
tail1.sources = src1
tail1.channels = ch1

tail1.sources.src1.type = exec
tail1.sources.src1.command = tail -F /logs/access.log
tail1.sources.src1.channels = ch1

tail1.channels.ch1.type = memory
tail1.channels.ch1.capacity = 10000
tail1.channels.ch1.transactionCapacity = 10000
tail1.channels.ch1.byteCapacityBufferPercentage = 20
tail1.channels.ch1.byteCapacity = 800000

tail1.sinks = sink1
tail1.sinks.sink1.type = avro
tail1.sinks.sink1.channel = ch1
tail1.sinks.sink1.batch-size = 1
tail1.sinks.sink1.hostname = hadoop1
tail1.sinks.sink1.port = 12345

\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\
--flume agent:rece1

rece1.sources = r1
rece1.channels = ch1
rece1.sources.r1.type = avro
rece1.sources.r1.channels = c1
rece1.sources.r1.bind = hadoop1
rece1.sources.r1.port = 12345

rece1.channels.ch1.type = memory
rece1.channels.ch1.capacity = 10000
rece1.channels.ch1.transactionCapacity = 10000
rece1.channels.ch1.byteCapacityBufferPercentage = 20
rece1.channels.ch1.byteCapacity = 800000

rece1.sinks = sink1
rece1.sinks.sink1.type = hdfs
rece1.sinks.sink1.channel = c1
rece1.sinks.sink1.hdfs.path = /flume/events/%y-%m-%d/%H%M/%S
rece1.sinks.sink1.hdfs.filePrefix = events-
rece1.sinks.sink1.hdfs.round = true
rece1.sinks.sink1.hdfs.roundValue = 10
rece1.sinks.sink1.hdfs.roundUnit = minute
\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\
flume agent:a1

a1.sources = r1
a1.sinks = k1
a1.channels = c1

# Describe/configure the source
a1.sources.r1.type = netcat
a1.sources.r1.bind = cdh6
a1.sources.r1.port = 12345

# Describe the sink
a1.sinks.k1.type = hdfs
a1.sinks.k1.hdfs.path = hdfs://cdh6:8020/tmp/
a1.sinks.k1.hdfs.writeFormat = Text
a1.sinks.k1.hdfs.fileType = DataStream
a1.sinks.k1.hdfs.rollInterval = 10
a1.sinks.k1.hdfs.rollSize = 0
a1.sinks.k1.hdfs.rollCount = 0
a1.sinks.k1.hdfs.filePrefix = %Y-%m-%d-%H-%M-%S
a1.sinks.k1.hdfs.useLocalTimeStamp = true

# Use a channel which buffers events in file
a1.channels.c1.type = file

# Bind the source and sink to the channel
a1.sources.r1.channels = c1
a1.sinks.k1.channel = c1

\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\
--SQOOP
[root@cdh6 ~]# mysql -uroot -p
Enter password: cloudera
Welcome to the MariaDB monitor.  Commands end with ; or \g.
Your MariaDB connection id is 545
Server version: 5.5.65-MariaDB MariaDB Server

Copyright (c) 2000, 2018, Oracle, MariaDB Corporation Ab and others.

Type 'help;' or '\h' for help. Type '\c' to clear the current input statement.

+--------------------+
| Database           |
+--------------------+
| information_schema |
| am                 |
| hue                |
| metastore          |
| mysql              |
| nav_as             |
| nav_ms             |
| oozie              |
| performance_schema |
| ranger             |
| retail_db          |
| rm                 |
| scm                |
| scott              |
| sentry             |
+--------------------+
15 rows in set (0.00 sec)

MariaDB [(none)]> use retail_db;
Reading table information for completion of table and column names
You can turn off this feature to get a quicker startup with -A

Database changed
MariaDB [retail_db]> show tables;
+---------------------+
| Tables_in_retail_db |
+---------------------+
| categories          |
| customers           |
| departments         |
| order_items         |
| orders              |
| products            |
+---------------------+
6 rows in set (0.00 sec)

MariaDB [retail_db]> desc customers;
+-------------------+--------------+------+-----+---------+----------------+
| Field             | Type         | Null | Key | Default | Extra          |
+-------------------+--------------+------+-----+---------+----------------+
| customer_id       | int(11)      | NO   | PRI | NULL    | auto_increment |
| customer_fname    | varchar(45)  | NO   |     | NULL    |                |
| customer_lname    | varchar(45)  | NO   |     | NULL    |                |
| customer_email    | varchar(45)  | NO   |     | NULL    |                |
| customer_password | varchar(45)  | NO   |     | NULL    |                |
| customer_street   | varchar(255) | NO   |     | NULL    |                |
| customer_city     | varchar(45)  | NO   |     | NULL    |                |
| customer_state    | varchar(45)  | NO   |     | NULL    |                |
| customer_zipcode  | varchar(45)  | NO   |     | NULL    |                |
+-------------------+--------------+------+-----+---------+----------------+
9 rows in set (0.00 sec)

MariaDB [retail_db]> select count(*) from customers;
+----------+
| count(*) |
+----------+
|    12435 |
+----------+
1 row in set (0.01 sec)

--SQOOP(SQL To Hadoop)
[cloudera@cdh6 ~]$ sqoop help
20/09/15 09:50:53 INFO sqoop.Sqoop: Running Sqoop version: 1.4.7-cdh6.3.2
usage: sqoop COMMAND [ARGS]

Available commands:
  codegen            Generate code to interact with database records
  create-hive-table  Import a table definition into Hive
  eval               Evaluate a SQL statement and display the results
  export             Export an HDFS directory to a database table
  help               List available commands
  import             Import a table from a database to HDFS
  import-all-tables  Import tables from a database to HDFS
  import-mainframe   Import datasets from a mainframe server to HDFS
  job                Work with saved jobs
  list-databases     List available databases on a server
  list-tables        List available tables in a database
  merge              Merge results of incremental imports
  metastore          Run a standalone Sqoop metastore
  version            Display version information

See 'sqoop help COMMAND' for information on a specific command.

--將mysql資料庫-retail_db的customers表格,匯入hdfs
--表格名字對應HDFS目錄名字,表格內容預設將分成4個CSV存放在HDFS目錄下(如果沒有明確指定位置,將自動放在執行sqoop這個os user相同名字的家目錄與表格名字相同的目錄裡)
                                                                      mysql的username/password可以連線與存取retail_db
                                                                      -----------------------------------
[cloudera@cdh6 ~]$ sqoop import --connect jdbc:mysql://cdh6/retail_db --username root --password cloudera --table customers 
                                                    ://mysqlserver/database
Warning: /opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/bin/../lib/sqoop/../accumulo does not exist! Accumulo imports will fail.
Please set $ACCUMULO_HOME to the root of your Accumulo installation.
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/jars/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/jars/log4j-slf4j-impl-2.8.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
20/09/14 16:19:19 INFO sqoop.Sqoop: Running Sqoop version: 1.4.7-cdh6.3.2
20/09/14 16:19:19 WARN tool.BaseSqoopTool: Setting your password on the command-line is insecure. Consider using -P instead.
20/09/14 16:19:19 INFO manager.MySQLManager: Preparing to use a MySQL streaming resultset.
20/09/14 16:19:19 INFO tool.CodeGenTool: Beginning code generation
20/09/14 16:19:20 INFO manager.SqlManager: Executing SQL statement: SELECT t.* FROM `customers` AS t LIMIT 1
20/09/14 16:19:20 INFO manager.SqlManager: Executing SQL statement: SELECT t.* FROM `customers` AS t LIMIT 1
20/09/14 16:19:20 INFO orm.CompilationManager: HADOOP_MAPRED_HOME is /opt/cloudera/parcels/CDH/lib/hadoop-mapreduce
20/09/14 16:19:22 ERROR orm.CompilationManager: Could not rename /tmp/sqoop-cloudera/compile/be472ed4270956b6c54ddac40b2981ec/customers.java to /home/cloudera/./customers.java. Error: Destination '/home/cloudera/./customers.java' already exists
20/09/14 16:19:22 INFO orm.CompilationManager: Writing jar file: /tmp/sqoop-cloudera/compile/be472ed4270956b6c54ddac40b2981ec/customers.jar  --sqoop生成mapreduce job
20/09/14 16:19:22 WARN manager.MySQLManager: It looks like you are importing from mysql.
20/09/14 16:19:22 WARN manager.MySQLManager: This transfer can be faster! Use the --direct
20/09/14 16:19:22 WARN manager.MySQLManager: option to exercise a MySQL-specific fast path.
20/09/14 16:19:22 INFO manager.MySQLManager: Setting zero DATETIME behavior to convertToNull (mysql)
20/09/14 16:19:22 INFO mapreduce.ImportJobBase: Beginning import of customers
20/09/14 16:19:22 INFO Configuration.deprecation: mapred.jar is deprecated. Instead, use mapreduce.job.jar
20/09/14 16:19:22 INFO Configuration.deprecation: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
20/09/14 16:19:23 INFO client.RMProxy: Connecting to ResourceManager at cdh6/192.168.56.103:8032
20/09/14 16:19:23 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /user/cloudera/.staging/job_1600045559460_0001
20/09/14 16:19:31 INFO db.DBInputFormat: Using read commited transaction isolation
20/09/14 16:19:31 INFO db.DataDrivenDBInputFormat: BoundingValsQuery: SELECT MIN(`customer_id`), MAX(`customer_id`) FROM `customers`   --customer_id為primary key
20/09/14 16:19:31 INFO db.IntegerSplitter: Split size: 3108; Num splits: 4 from: 1 to: 12435
20/09/14 16:19:31 INFO mapreduce.JobSubmitter: number of splits:4
20/09/14 16:19:31 INFO Configuration.deprecation: yarn.resourcemanager.system-metrics-publisher.enabled is deprecated. Instead, use yarn.system-metrics-publisher.enabled
20/09/14 16:19:32 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1600045559460_0001
20/09/14 16:19:32 INFO mapreduce.JobSubmitter: Executing with tokens: []
20/09/14 16:19:32 INFO conf.Configuration: resource-types.xml not found
20/09/14 16:19:32 INFO resource.ResourceUtils: Unable to find 'resource-types.xml'.
20/09/14 16:19:32 INFO impl.YarnClientImpl: Submitted application application_1600045559460_0001
20/09/14 16:19:33 INFO mapreduce.Job: The url to track the job: http://cdh6:8088/proxy/application_1600045559460_0001/
20/09/14 16:19:33 INFO mapreduce.Job: Running job: job_1600045559460_0001
20/09/14 16:19:42 INFO mapreduce.Job: Job job_1600045559460_0001 running in uber mode : false
20/09/14 16:19:42 INFO mapreduce.Job:  map 0% reduce 0%
20/09/14 16:19:50 INFO mapreduce.Job:  map 75% reduce 0%
20/09/14 16:19:54 INFO mapreduce.Job:  map 100% reduce 0%
20/09/14 16:19:54 INFO mapreduce.Job: Job job_1600045559460_0001 completed successfully
20/09/14 16:19:54 INFO mapreduce.Job: Counters: 33
        File System Counters
                FILE: Number of bytes read=0
                FILE: Number of bytes written=970436
                FILE: Number of read operations=0
                FILE: Number of large read operations=0
                FILE: Number of write operations=0
                HDFS: Number of bytes read=479
                HDFS: Number of bytes written=953525
                HDFS: Number of read operations=24
                HDFS: Number of large read operations=0
                HDFS: Number of write operations=8
                HDFS: Number of bytes read erasure-coded=0
        Job Counters
                Launched map tasks=4                                               --4個mapper同時進行導出customers到/user/cloudera/customers
                Other local map tasks=4
                Total time spent by all maps in occupied slots (ms)=19707
                Total time spent by all reduces in occupied slots (ms)=0
                Total time spent by all map tasks (ms)=19707
                Total vcore-milliseconds taken by all map tasks=19707
                Total megabyte-milliseconds taken by all map tasks=20179968
        Map-Reduce Framework
                Map input records=12435
                Map output records=12435
                Input split bytes=479
                Spilled Records=0
                Failed Shuffles=0
                Merged Map outputs=0
                GC time elapsed (ms)=743
                CPU time spent (ms)=8050
                Physical memory (bytes) snapshot=1124220928
                Virtual memory (bytes) snapshot=10406252544
                Total committed heap usage (bytes)=1083703296
                Peak Map Physical memory (bytes)=301228032
                Peak Map Virtual memory (bytes)=2603130880
        File Input Format Counters
                Bytes Read=0
        File Output Format Counters
                Bytes Written=953525
20/09/14 16:19:54 INFO mapreduce.ImportJobBase: Transferred 931.1768 KB in 31.4177 seconds (29.6386 KB/sec)
20/09/14 16:19:54 INFO mapreduce.ImportJobBase: Retrieved 12435 records.


                                                     ---------表格名字對應為目錄名字
[cloudera@cdh6 ~]$ hdfs dfs -ls /user/cloudera/customers/
Found 5 items
-rw-r--r--   1 cloudera cloudera          0 2019-06-24 00:41 /user/cloudera/customers/_SUCCESS
-rw-r--r--   1 cloudera cloudera     237145 2019-06-24 00:41 /user/cloudera/customers/part-m-00000    --part-m表示為mapper生成的檔案,m-00000表示為第一個mapper
-rw-r--r--   1 cloudera cloudera     237965 2019-06-24 00:41 /user/cloudera/customers/part-m-00001    --預設為CSV格式
-rw-r--r--   1 cloudera cloudera     238092 2019-06-24 00:41 /user/cloudera/customers/part-m-00002
-rw-r--r--   1 cloudera cloudera     240323 2019-06-24 00:41 /user/cloudera/customers/part-m-00003

[cloudera@cdh6 ~]$ hdfs dfs -cat /user/cloudera/customers/part-m-00000
3095,Patricia,Hayes,XXXXXXXXX,XXXXXXXXX,5755 Thunder Nectar Gate,Caguas,PR,00725
3096,Stephanie,Larson,XXXXXXXXX,XXXXXXXXX,3050 Cinder End,Lynn,MA,01902
3097,Douglas,Hanna,XXXXXXXXX,XXXXXXXXX,1112 Rustic Range,Caguas,PR,00725
3098,Mary,Smith,XXXXXXXXX,XXXXXXXXX,8217 Fallen Panda Walk,Newburgh,NY,12550
3099,Brittany,Copeland,XXXXXXXXX,XXXXXXXXX,5735 Round Beacon Terrace,Caguas,PR,00725
3100,Mary,Smith,XXXXXXXXX,XXXXXXXXX,5436 Grand Hickory Farm,Huntington Park,CA,90255
3101,George,Reyes,XXXXXXXXX,XXXXXXXXX,8702 Silver Apple Square,Mission Viejo,CA,92692
3102,Ralph,Dixon,XXXXXXXXX,XXXXXXXXX,5633 Harvest Turnabout,Caguas,PR,00725
3103,Mary,Wilkins,XXXXXXXXX,XXXXXXXXX,1213 Cotton Pike,Spring Valley,NY,10977
3104,Megan,Smith,XXXXXXXXX,XXXXXXXXX,5292 Shady Pony Cape,Caguas,PR,00725
3105,Mary,Stone,XXXXXXXXX,XXXXXXXXX,8510 Green River Acres,Toa Baja,PR,00949
3106,Samantha,Smith,XXXXXXXXX,XXXXXXXXX,355 Cozy Square,Las Cruces,NM,88005
3107,Tiffany,Estes,XXXXXXXXX,XXXXXXXXX,5182 Cotton Heath,Caguas,PR,00725
3108,Mary,Smith,XXXXXXXXX,XXXXXXXXX,577 Rustic Nectar Row,Houston,TX,77083
3109,Jack,James,XXXXXXXXX,XXXXXXXXX,5876 Burning Mall ,Fort Worth,TX,76133

--從HDFS將一個目錄下載到Local Filesystem的一個目錄
[cloudera@cdh6 ~]$ hdfs dfs -get /user/cloudera/customers customers
[cloudera@cdh6 ~]$ ls -l customers
total 940
-rw-r--r-- 1 cloudera cloudera 237145 Sep 23 18:52 part-m-00000
-rw-r--r-- 1 cloudera cloudera 237965 Sep 23 18:52 part-m-00001
-rw-r--r-- 1 cloudera cloudera 238092 Sep 23 18:52 part-m-00002
-rw-r--r-- 1 cloudera cloudera 240323 Sep 23 18:52 part-m-00003
-rw-r--r-- 1 cloudera cloudera      0 Sep 23 18:52 _SUCCESS

--從HDFS將一個目錄下載到Local Filesystem的一個檔案
[cloudera@cdh6 ~]$ rm -rf customers
[cloudera@cdh6 ~]$ hdfs dfs -getmerge /user/cloudera/customers customers
[cloudera@cdh6 ~]$ ls -l customers
-rw-r--r-- 1 cloudera cloudera 953525 Sep 23 18:54 customers
[cloudera@cdh6 ~]$ tail customers
12426,Jordan,Valdez,XXXXXXXXX,XXXXXXXXX,5561 Quiet Loop,Brooklyn,NY,11210
12427,Mary,Smith,XXXXXXXXX,XXXXXXXXX,3662 Round Barn Gate,Plano,TX,75093
12428,Jeffrey,Travis,XXXXXXXXX,XXXXXXXXX,1552 Burning Dale Highlands,Caguas,PR,00725
12429,Mary,Smith,XXXXXXXXX,XXXXXXXXX,92 Sunny Bear Villas,Gardena,CA,90247
12430,Hannah,Brown,XXXXXXXXX,XXXXXXXXX,8316 Pleasant Bend,Caguas,PR,00725
12431,Mary,Rios,XXXXXXXXX,XXXXXXXXX,1221 Cinder Pines,Kaneohe,HI,96744
12432,Angela,Smith,XXXXXXXXX,XXXXXXXXX,1525 Jagged Barn Highlands,Caguas,PR,00725
12433,Benjamin,Garcia,XXXXXXXXX,XXXXXXXXX,5459 Noble Brook Landing,Levittown,NY,11756
12434,Mary,Mills,XXXXXXXXX,XXXXXXXXX,9720 Colonial Parade,Caguas,PR,00725
12435,Laura,Horton,XXXXXXXXX,XXXXXXXXX,5736 Honey Downs,Summerville,SC,29483

                                      sqoop將會建立
                                      ---------
--target-dir /user/cloudera/retail_db/customers
             ------------------------
		     必須先存在
[cloudera@cdh6 ~]$ sqoop import --connect jdbc:mysql://cdh6/retail_db --username root --password cloudera --table customers --target-dir /user/cloudera/retail_db/customers
[cloudera@cdh6 ~]$ hdfs dfs -ls /user/cloudera/retail_db/
Found 1 items
drwxr-xr-x   - cloudera cloudera          0 2019-09-23 19:02 /user/cloudera/retail_db/customers

-- -rm刪除檔案 , -rm -r刪除目錄及檔案
[cloudera@cdh6 ~]$ hdfs dfs -rm -r /user/cloudera/retail_db/customers
19/09/23 19:04:02 INFO fs.TrashPolicyDefault: Moved: 'hdfs://cdh6:8020/user/cloudera/retail_db/customers' to trash at: hdfs://cdh6:8020/user/cloudera/.Trash/Current/user/cloudera/retail_db/customers
[cloudera@cdh6 ~]$ hdfs dfs -ls /user/cloudera/.Trash
Found 2 items
drwx------   - cloudera cloudera          0 2019-06-28 01:22 /user/cloudera/.Trash/190922230000
drwx------   - cloudera cloudera          0 2019-09-23 19:04 /user/cloudera/.Trash/Current
[cloudera@cdh6 ~]$ hdfs dfs -ls /user/cloudera/.Trash/Current/
Found 1 items
drwx------   - cloudera cloudera          0 2019-09-23 19:04 /user/cloudera/.Trash/Current/user

[cloudera@cdh6 ~]$ hdfs dfs -ls /user/cloudera/.Trash/Current/user/cloudera/
Found 1 items
drwx------   - cloudera cloudera          0 2019-09-23 19:04 /user/cloudera/.Trash/Current/user/cloudera/retail_db
[cloudera@cdh6 ~]$ hdfs dfs -ls /user/cloudera/.Trash/Current/user/cloudera/retail_db/customers/
Found 5 items
-rw-r--r--   1 cloudera cloudera          0 2019-09-23 19:02 /user/cloudera/.Trash/Current/user/cloudera/retail_db/customers/_SUCCESS
-rw-r--r--   1 cloudera cloudera     237145 2019-09-23 19:02 /user/cloudera/.Trash/Current/user/cloudera/retail_db/customers/part-m-00000
-rw-r--r--   1 cloudera cloudera     237965 2019-09-23 19:02 /user/cloudera/.Trash/Current/user/cloudera/retail_db/customers/part-m-00001
-rw-r--r--   1 cloudera cloudera     238092 2019-09-23 19:02 /user/cloudera/.Trash/Current/user/cloudera/retail_db/customers/part-m-00002
-rw-r--r--   1 cloudera cloudera     240323 2019-09-23 19:02 /user/cloudera/.Trash/Current/user/cloudera/retail_db/customers/part-m-00003

                                                    
-- warehouse-dir /user/cloudera/retail_db/customers
                 ----------------------------------
				 已經存在
--將sqoop執行後,將自動在/user/cloudera/retail_db/customers/建立一個與table名字相同的目錄
--在此範例中為/user/cloudera/retail_db/customers/customers				 
[cloudera@cdh6 ~]$ sqoop import --connect jdbc:mysql://cdh6/retail_db --username root --password cloudera --table customers --warehouse-dir /user/cloudera/retail_db/customers
[cloudera@cdh6 ~]$ hdfs dfs -ls /user/cloudera/retail_db/
Found 1 items
drwxr-xr-x   - cloudera cloudera          0 2019-09-23 19:09 /user/cloudera/retail_db/customers
[cloudera@cdh6 ~]$ hdfs dfs -ls /user/cloudera/retail_db/customers/
Found 1 items
drwxr-xr-x   - cloudera cloudera          0 2019-09-23 19:09 /user/cloudera/retail_db/customers/customers
[cloudera@cdh6 ~]$ hdfs dfs -ls /user/cloudera/retail_db/customers/customers
Found 5 items
-rw-r--r--   1 cloudera cloudera          0 2019-09-23 19:09 /user/cloudera/retail_db/customers/customers/_SUCCESS
-rw-r--r--   1 cloudera cloudera     237145 2019-09-23 19:09 /user/cloudera/retail_db/customers/customers/part-m-00000
-rw-r--r--   1 cloudera cloudera     237965 2019-09-23 19:09 /user/cloudera/retail_db/customers/customers/part-m-00001
-rw-r--r--   1 cloudera cloudera     238092 2019-09-23 19:09 /user/cloudera/retail_db/customers/customers/part-m-00002
-rw-r--r--   1 cloudera cloudera     240323 2019-09-23 19:09 /user/cloudera/retail_db/customers/customers/part-m-00003

--請注意--target-dir與--warehouse-dir的目錄格式

[cloudera@cdh6 ~]$ sqoop list-databases --connect jdbc:mysql://cdh6 --username root --password cloudera

information_schema
am
hue
metastore
mysql
nav_as
nav_ms
oozie
performance_schema
ranger
retail_db
rm
scm
scott
sentry

[cloudera@cdh6 ~]$ mysql -uroot -pcloudera
MariaDB [(none)]> show databases;
+--------------------+
| Database           |
+--------------------+
| information_schema |
| am                 |
| hue                |
| metastore          |
| mysql              |
| nav_as             |
| nav_ms             |
| oozie              |
| performance_schema |
| ranger             |
| retail_db          |
| rm                 |
| scm                |
| scott              |
| sentry             |
+--------------------+
15 rows in set (0.00 sec)

MariaDB [(none)]> create database newdb;
Query OK, 1 row affected (0.00 sec)

MariaDB [(none)]> use newdb
Database changed
MariaDB [newdb]> show tables;
Empty set (0.00 sec)

MariaDB [newdb]> create table customers like retail_db.customers;
Query OK, 0 rows affected (0.01 sec)

MariaDB [newdb]> select count(*) from customers;
+----------+
| count(*) |
+----------+
|        0 |  -等一會使用sqoop export從hdfs讀取資料載入此表格
+----------+
1 row in set (0.00 sec)

--使用sqoop export從hdfs讀取資料載入此表格
[cloudera@cdh6 ~]$ sqoop export --connect jdbc:mysql://cdh6/newdb --username root --password cloudera --table customers --export-dir /user/cloudera/customers 
20/09/15 10:13:07 INFO mapreduce.Job: Counters: 33
        File System Counters
                FILE: Number of bytes read=0
                FILE: Number of bytes written=727359
                FILE: Number of read operations=0
                FILE: Number of large read operations=0
                FILE: Number of write operations=0
                HDFS: Number of bytes read=964993
                HDFS: Number of bytes written=0
                HDFS: Number of read operations=18
                HDFS: Number of large read operations=0
                HDFS: Number of write operations=0
                HDFS: Number of bytes read erasure-coded=0
        Job Counters
                Launched map tasks=3
                Data-local map tasks=3
                Total time spent by all maps in occupied slots (ms)=14281
                Total time spent by all reduces in occupied slots (ms)=0
                Total time spent by all map tasks (ms)=14281
                Total vcore-milliseconds taken by all map tasks=14281
                Total megabyte-milliseconds taken by all map tasks=14623744
        Map-Reduce Framework
                Map input records=12435
                Map output records=12435
                Input split bytes=542
                Spilled Records=0
                Failed Shuffles=0
                Merged Map outputs=0
                GC time elapsed (ms)=634
                CPU time spent (ms)=6940
                Physical memory (bytes) snapshot=900354048
                Virtual memory (bytes) snapshot=7802433536
                Total committed heap usage (bytes)=940048384
                Peak Map Physical memory (bytes)=304328704
                Peak Map Virtual memory (bytes)=2602684416
        File Input Format Counters
                Bytes Read=0
        File Output Format Counters
                Bytes Written=0
20/09/15 10:13:07 INFO mapreduce.ExportJobBase: Transferred 942.376 KB in 21.5166 seconds (43.7977 KB/sec)
20/09/15 10:13:07 INFO mapreduce.ExportJobBase: Exported 12435 records.

--確認載入結果
mysql> select count(*) from customers;
+----------+
| count(*) |
+----------+
|    12435 |
+----------+
1 row in set (0.00 sec)

--顯示某個資料庫的所有表格
[cloudera@cdh6 ~]$ sqoop list-tables --connect jdbc:mysql://cdh6/newdb --username root --password cloudera
                                                                 database name
customers

																 
\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\
[cloudera@cdh6 ~]$ hive
hive> show databases;
OK
default
Time taken: 1.279 seconds, Fetched: 1 row(s)
hive> use default;
OK
Time taken: 0.03 seconds
hive> show tables;
OK
sample_07
sample_08
web_logs
Time taken: 0.078 seconds, Fetched: 3 row(s)
\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\			  
--如果加上--hive等參數,可以在載入資料到hdfs後,順便建立hive的metadata
--如果表格已經存在,則拿掉--create-hive-table,改為--hive-overwrite

[cloudera@cdh6 ~]$ sqoop import --connect jdbc:mysql://cdh6/retail_db --username root --password cloudera --table customers \
                                      --hive-import --create-hive-table --hive-database default --warehouse-dir /user/hive/warehouse
                                
								對hive而言,此目錄為default資料庫,每個位於default資料庫的表格,預設有一個與表格名字相同的子目錄
							    ---------------------
[cloudera@cdh6 ~]$ hdfs dfs -ls /user/hive/warehouse/
Found 4 items
drwxr-xr-x   - cloudera hive          0 2020-09-15 10:28 /user/hive/warehouse/customers
drwxrwxrwt   - admin    hive          0 2020-09-03 16:32 /user/hive/warehouse/sample_07
drwxrwxrwt   - admin    hive          0 2020-09-03 16:32 /user/hive/warehouse/sample_08
drwxrwxrwt   - admin    hive          0 2020-09-03 16:32 /user/hive/warehouse/web_logs

[cloudera@cdh6 ~]$ hdfs dfs -ls /user/hive/warehouse/customers/
Found 5 items
-rw-r--r--   1 cloudera hive          0 2020-09-15 10:28 /user/hive/warehouse/customers/_SUCCESS
-rwxr-xr-x   1 cloudera hive     237145 2020-09-15 10:27 /user/hive/warehouse/customers/part-m-00000
-rwxr-xr-x   1 cloudera hive     237965 2020-09-15 10:27 /user/hive/warehouse/customers/part-m-00001
-rwxr-xr-x   1 cloudera hive     238092 2020-09-15 10:27 /user/hive/warehouse/customers/part-m-00002
-rwxr-xr-x   1 cloudera hive     240323 2020-09-15 10:28 /user/hive/warehouse/customers/part-m-00003

--啟動Hive查看sqoop所生的表格與資料
[cloudera@cdh6 ~]$ hive

Logging initialized using configuration in jar:file:/usr/lib/hive/lib/hive-common-1.1.0-cdh5.13.0.jar!/hive-log4j.properties
WARNING: Hive CLI is deprecated and migration to Beeline is recommended.
hive> show databases;
OK
default
Time taken: 3.356 seconds, Fetched: 1 row(s)
hive> use default;
OK
Time taken: 0.067 seconds
hive> show tables;
OK
customers
sample_07
sample_08
web_logs
Time taken: 0.031 seconds, Fetched: 4 row(s)

hive> desc customers;
OK
customer_id         	int                 	                    
customer_fname      	string              	                    
customer_lname      	string              	                    
customer_email      	string              	                    
customer_password   	string              	                    
customer_street     	string              	                    
customer_city       	string              	                    
customer_state      	string              	                    
customer_zipcode    	string              	                    
Time taken: 0.22 seconds, Fetched: 9 row(s)

hive> desc formatted customers;
OK
# col_name              data_type               comment

customer_id             int
customer_fname          string
customer_lname          string
customer_email          string
customer_password       string
customer_street         string
customer_city           string
customer_state          string
customer_zipcode        string

# Detailed Table Information
Database:               default
OwnerType:              USER
Owner:                  cloudera
CreateTime:             Tue Sep 15 10:28:08 CST 2020
LastAccessTime:         UNKNOWN
Retention:              0
Location:               hdfs://cdh6:8020/user/hive/warehouse/customers           --表格資料
Table Type:             MANAGED_TABLE
Table Parameters:
        comment                 Imported by sqoop on 2020/09/15 10:28:04
        numFiles                4
        numRows                 0
        rawDataSize             0
        totalSize               953525
        transient_lastDdlTime   1600136889

# Storage Information
SerDe Library:          org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
InputFormat:            org.apache.hadoop.mapred.TextInputFormat
OutputFormat:           org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
Compressed:             No
Num Buckets:            -1
Bucket Columns:         []
Sort Columns:           []
Storage Desc Params:
        field.delim             \u0001
        line.delim              \n
        serialization.format    \u0001
Time taken: 0.103 seconds, Fetched: 41 row(s)

hive> select customer_city,count(*) cust_count from customers group by customer_city order by cust_count desc limit 5;
Query ID = cloudera_20200915103236_a7afce7b-f47b-4b84-9f22-49979a63f4f0
Total jobs = 2
Launching Job 1 out of 2
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
20/09/15 10:32:37 INFO client.RMProxy: Connecting to ResourceManager at cdh6/192.168.56.103:8032
20/09/15 10:32:37 INFO client.RMProxy: Connecting to ResourceManager at cdh6/192.168.56.103:8032
Starting Job = job_1600045559460_0004, Tracking URL = http://cdh6:8088/proxy/application_1600045559460_0004/
Kill Command = /opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/bin/hadoop job  -kill job_1600045559460_0004
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2020-09-15 10:32:45,319 Stage-1 map = 0%,  reduce = 0%
2020-09-15 10:32:50,458 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 2.25 sec
2020-09-15 10:32:55,567 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 3.92 sec
MapReduce Total cumulative CPU time: 3 seconds 920 msec
Ended Job = job_1600045559460_0004
Launching Job 2 out of 2
Number of reduce tasks determined at compile time: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
20/09/15 10:32:57 INFO client.RMProxy: Connecting to ResourceManager at cdh6/192.168.56.103:8032
20/09/15 10:32:57 INFO client.RMProxy: Connecting to ResourceManager at cdh6/192.168.56.103:8032
Starting Job = job_1600045559460_0005, Tracking URL = http://cdh6:8088/proxy/application_1600045559460_0005/
Kill Command = /opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/bin/hadoop job  -kill job_1600045559460_0005
Hadoop job information for Stage-2: number of mappers: 1; number of reducers: 1
2020-09-15 10:33:06,594 Stage-2 map = 0%,  reduce = 0%
2020-09-15 10:33:12,706 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 1.58 sec
2020-09-15 10:33:18,821 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 3.33 sec
MapReduce Total cumulative CPU time: 3 seconds 330 msec
Ended Job = job_1600045559460_0005
MapReduce Jobs Launched:
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 3.92 sec   HDFS Read: 962652 HDFS Write: 15754 HDFS EC Read: 0 SUCCESS
Stage-Stage-2: Map: 1  Reduce: 1   Cumulative CPU: 3.33 sec   HDFS Read: 21353 HDFS Write: 213 HDFS EC Read: 0 SUCCESS
Total MapReduce CPU Time Spent: 7 seconds 250 msec
OK
Caguas  4584
Chicago 274
Brooklyn        225
Los Angeles     224
New York        120
Time taken: 43.192 seconds, Fetched: 5 row(s)   --MR Job所耗費時間

--Hive on Spark
hive> set hive.execution.engine=spark;
hive> select customer_city,count(*) cust_count from customers group by customer_city order by cust_count desc limit 5;
Query ID = cloudera_20200915103411_2823d9ed-79dc-457e-869e-7b40a597bf3a
Total jobs = 1
Launching Job 1 out of 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Running with YARN Application = application_1600045559460_0006
Kill Command = /opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/bin/yarn application -kill application_1600045559460_0006
Hive on Spark Session Web UI URL: http://cdh6:41093

Query Hive on Spark job[0] stages: [0, 1, 2]
Spark job[0] status = RUNNING
--------------------------------------------------------------------------------------
          STAGES   ATTEMPT        STATUS  TOTAL  COMPLETED  RUNNING  PENDING  FAILED
--------------------------------------------------------------------------------------
Stage-0 ........         0      FINISHED      1          1        0        0       0
Stage-1 ........         0      FINISHED      1          1        0        0       0
Stage-2 ........         0      FINISHED      1          1        0        0       0
--------------------------------------------------------------------------------------
STAGES: 03/03    [==========================>>] 100%  ELAPSED TIME: 7.07 s
--------------------------------------------------------------------------------------
Spark job[0] finished successfully in 7.07 second(s)
Spark Job[0] Metrics: TaskDurationTime: 3578, ExecutorCpuTime: 1360, JvmGCTime: 92, BytesRead / RecordsRead: 958805 / 12435, BytesReadEC: 0, ShuffleTotalBytesRead / ShuffleRecordsRead: 10555 / 567, ShuffleBytesWritten / ShuffleRecordsWritten: 10555 / 567
OK
Caguas  4584
Chicago 274
Brooklyn        225
Los Angeles     224
New York        120
Time taken: 24.559 seconds, Fetched: 5 row(s)    --Spark Job所耗費時間

--在執行第2次
hive> select customer_city,count(*) cust_count from customers group by customer_city order by cust_count desc limit 5;
Query ID = cloudera_20200915103552_e2cd9f8a-3a35-47e3-8c65-8fb5aa698cd3
Total jobs = 1
Launching Job 1 out of 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Running with YARN Application = application_1600045559460_0006
Kill Command = /opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/bin/yarn application -kill application_1600045559460_0006
Hive on Spark Session Web UI URL: http://cdh6:41093

Query Hive on Spark job[1] stages: [5, 3, 4]
Spark job[1] status = RUNNING
--------------------------------------------------------------------------------------
          STAGES   ATTEMPT        STATUS  TOTAL  COMPLETED  RUNNING  PENDING  FAILED
--------------------------------------------------------------------------------------
Stage-3 ........         0      FINISHED      1          1        0        0       0
Stage-4 ........         0      FINISHED      1          1        0        0       0
Stage-5 ........         0      FINISHED      1          1        0        0       0
--------------------------------------------------------------------------------------
STAGES: 03/03    [==========================>>] 100%  ELAPSED TIME: 2.02 s
--------------------------------------------------------------------------------------
Spark job[1] finished successfully in 2.02 second(s)
Spark Job[1] Metrics: TaskDurationTime: 402, ExecutorCpuTime: 217, JvmGCTime: 16, BytesRead / RecordsRead: 959721 / 12435, BytesReadEC: 0, ShuffleTotalBytesRead / ShuffleRecordsRead: 10555 / 567, ShuffleBytesWritten / ShuffleRecordsWritten: 10555 / 567
OK
Caguas  4584
Chicago 274
Brooklyn        225
Los Angeles     224
New York        120
Time taken: 2.145 seconds, Fetched: 5 row(s)   --第2次執行較第1次快許多(因為第1次執行時,會啟動相關的spark環境,而這些環境在此hive session持續情況下,不會關閉,所以後續執行速度會變快)

[cloudera@cdh6 ~]$ hdfs dfs -put /etc/passwd
[cloudera@cdh6 ~]$ hdfs dfs -ls /user/cloudera/passwd
-rw-r--r--   1 cloudera supergroup       3509 2020-09-15 11:16 /user/cloudera/passwd

[cloudera@cdh6 ~]$ hdfs dfs -cat /user/cloudera/passwd

--請注意,使用webHDFS時,http所連線的主機為NameNode(Active)的webUI port
                                     -----------------------
[cloudera@cdh6 ~]$ curl -i -L "http://cdh6:9870/webhdfs/v1/user/cloudera/passwd?op=OPEN&user.name=cloudera"
                                                          ---------------------
																											   
HTTP/1.1 307 Temporary Redirect
Date: Tue, 15 Sep 2020 03:17:38 GMT
Cache-Control: no-cache
Expires: Tue, 15 Sep 2020 03:17:38 GMT
Date: Tue, 15 Sep 2020 03:17:38 GMT
Pragma: no-cache
X-Content-Type-Options: nosniff
X-FRAME-OPTIONS: SAMEORIGIN
X-XSS-Protection: 1; mode=block
Set-Cookie: hadoop.auth="u=cloudera&p=cloudera&t=simple&e=1600175858493&s=r4u5XlvNmsnHYlRdLWIMR3/3enNYasPZfzuaDJT/uPY="; Path=/; HttpOnly
Location: http://cdh6:9864/webhdfs/v1/user/cloudera/passwd?op=OPEN&user.name=cloudera&namenoderpcaddress=cdh6:8020&offset=0   --9864為Data Node的WebIUI port
Content-Type: application/octet-stream
Content-Length: 0

HTTP/1.1 200 OK
Access-Control-Allow-Methods: GET
Access-Control-Allow-Origin: *
Content-Type: application/octet-stream
Connection: close
Content-Length: 3509

root:x:0:0:root:/root:/bin/bash
bin:x:1:1:bin:/bin:/sbin/nologin
daemon:x:2:2:daemon:/sbin:/sbin/nologin
adm:x:3:4:adm:/var/adm:/sbin/nologin
lp:x:4:7:lp:/var/spool/lpd:/sbin/nologin
sync:x:5:0:sync:/sbin:/bin/sync
shutdown:x:6:0:shutdown:/sbin:/sbin/shutdown
halt:x:7:0:halt:/sbin:/sbin/halt
mail:x:8:12:mail:/var/spool/mail:/sbin/nologin
uucp:x:10:14:uucp:/var/spool/uucp:/sbin/nologin
operator:x:11:0:operator:/root:/sbin/nologin
games:x:12:100:games:/usr/games:/sbin/nologin
gopher:x:13:30:gopher:/var/gopher:/sbin/nologin
ftp:x:14:50:FTP User:/var/ftp:/sbin/nologin
nobody:x:99:99:Nobody:/:/sbin/nologin
dbus:x:81:81:System message bus:/:/sbin/nologin
vcsa:x:69:69:virtual console memory owner:/dev:/sbin/nologin
abrt:x:173:173::/etc/abrt:/sbin/nologin
haldaemon:x:68:68:HAL daemon:/:/sbin/nologin
ntp:x:38:38::/etc/ntp:/sbin/nologin
saslauth:x:499:76:Saslauthd user:/var/empty/saslauth:/sbin/nologin
postfix:x:89:89::/var/spool/postfix:/sbin/nologin
sshd:x:74:74:Privilege-separated SSH:/var/empty/sshd:/sbin/nologin
tcpdump:x:72:72::/:/sbin/nologin
zookeeper:x:498:499:ZooKeeper:/var/lib/zookeeper:/sbin/nologin
cloudera-scm:x:497:498:Cloudera Manager:/var/lib/cloudera-scm-server:/sbin/nologin
rpc:x:32:32:Rpcbind Daemon:/var/cache/rpcbind:/sbin/nologin
apache:x:48:48:Apache:/var/www:/sbin/nologin
solr:x:496:496:Solr:/var/lib/solr:/sbin/nologin
hbase:x:495:495:HBase:/var/lib/hbase:/sbin/nologin
sentry:x:494:494:Sentry:/var/lib/sentry:/sbin/nologin
hive:x:493:493:Hive:/var/lib/hive:/sbin/nologin
hdfs:x:492:491:Hadoop HDFS:/var/lib/hadoop-hdfs:/bin/bash
yarn:x:491:490:Hadoop Yarn:/var/lib/hadoop-yarn:/bin/bash
impala:x:490:489:Impala:/var/lib/impala:/bin/bash
mapred:x:489:488:Hadoop MapReduce:/var/lib/hadoop-mapreduce:/bin/bash
hue:x:488:487:Hue:/usr/lib/hue:/sbin/nologin
sqoop:x:487:486:Sqoop:/var/lib/sqoop:/sbin/nologin
flume:x:486:485:Flume:/var/lib/flume-ng:/sbin/nologin
spark:x:485:484:Spark:/var/lib/spark:/sbin/nologin
sqoop2:x:484:486:Sqoop 2 User:/var/lib/sqoop2:/sbin/nologin
oozie:x:483:483:Oozie User:/var/lib/oozie:/bin/false
mysql:x:27:27:MySQL Server:/var/lib/mysql:/bin/bash
kms:x:482:482:Hadoop KMS:/var/lib/hadoop-kms:/bin/bash
llama:x:500:481:Llama:/var/lib/llama:/bin/bash
httpfs:x:481:480:Hadoop HTTPFS:/var/lib/hadoop-httpfs:/bin/bash
gdm:x:42:42::/var/lib/gdm:/sbin/nologin
rtkit:x:480:477:RealtimeKit:/proc:/sbin/nologin
pulse:x:479:476:PulseAudio System Daemon:/var/run/pulse:/sbin/nologin
avahi-autoipd:x:170:170:Avahi IPv4LL Stack:/var/lib/avahi-autoipd:/sbin/nologin
cloudera:x:501:501::/home/cloudera:/bin/bash
vboxadd:x:478:1::/var/run/vboxadd:/bin/false

--如果直接使用Browser輸入此url "http://cdh6:9870/webhdfs/v1/user/cloudera/passwd?op=OPEN&user.name=cloudera"
HTTP/1.1 200 OK
Date: Tue, 15 Sep 2020 03:19:31 GMT
Cache-Control: no-cache
Expires: Tue, 15 Sep 2020 03:19:31 GMT
Date: Tue, 15 Sep 2020 03:19:31 GMT
Pragma: no-cache
X-Content-Type-Options: nosniff
X-FRAME-OPTIONS: SAMEORIGIN
X-XSS-Protection: 1; mode=block
Set-Cookie: hadoop.auth="u=cloudera&p=cloudera&t=simple&e=1600175971772&s=K73y/mRe6GsFOFw7SpDVebPy+oEvFRQzmZO+Oh5u/2s="; Path=/; HttpOnly
Content-Type: application/json
Transfer-Encoding: chunked
{"boolean":true}

--建立一個子目錄 /user/cloudera/testdir
[cloudera@cdh6 ~]$ curl -i -X PUT "http://cdh6:9870/webhdfs/v1/user/cloudera/testdir?op=MKDIRS&user.name=cloudera"
HTTP/1.1 200 OK
Cache-Control: no-cache
Expires: Tue, 24 Sep 2019 03:31:55 GMT
Date: Tue, 24 Sep 2019 03:31:55 GMT
Pragma: no-cache
Expires: Tue, 24 Sep 2019 03:31:55 GMT
Date: Tue, 24 Sep 2019 03:31:55 GMT
Pragma: no-cache
Content-Type: application/json
X-FRAME-OPTIONS: SAMEORIGIN
Set-Cookie: hadoop.auth="u=cloudera&p=cloudera&t=simple&e=1569331915990&s=2z82yq9/m7c5vGTtMYmSz75uwSI="; Path=/; HttpOnly
Transfer-Encoding: chunked

{"boolean":true}
[cloudera@cdh6 ~]$ hdfs dfs -ls /user/cloudera
Found 11 items
drwx------   - cloudera cloudera          0 2019-09-23 20:31 /user/cloudera/.Trash
drwxr-xr-x   - cloudera cloudera          0 2019-06-28 01:20 /user/cloudera/.sparkStaging
drwx------   - cloudera cloudera          0 2019-09-23 19:57 /user/cloudera/.staging
-rw-r--r--   1 cloudera cloudera         80 2019-06-26 22:30 /user/cloudera/dept1.csv
-rw-r--r--   1 cloudera cloudera        650 2019-06-26 08:34 /user/cloudera/emp.csv
-rw-r--r--   1 cloudera cloudera        617 2019-06-26 19:38 /user/cloudera/emp1.csv
-rw-r--r--   1 cloudera cloudera       2652 2019-09-23 20:14 /user/cloudera/passwd
drwxr-xr-x   - cloudera cloudera          0 2019-09-23 19:09 /user/cloudera/retail_db
-rw-r--r--   1 cloudera cloudera    5444257 2019-09-23 00:18 /user/cloudera/shakespeare.txt
-rw-r--r--   1 cloudera cloudera    5444257 2019-09-23 00:28 /user/cloudera/shakespeare_1M.txt
drwxr-xr-x   - cloudera cloudera          0 2019-09-23 20:31 /user/cloudera/testdir  --剛剛建立的目錄
[cloudera@cdh6 ~]$


                                      local file         連線到NameNode
									  -----------        ----------------
[cloudera@cdh6 ~]$ curl -i -X PUT -T /etc/passwd "http://cdh6:9870/webhdfs/v1/user/cloudera/testdir/passwd?op=CREATE&user.name=cloudera"
HTTP/1.1 100 Continue                                                                    -----------------------------
                                                                                         HDFS file
HTTP/1.1 307 Temporary Redirect
Date: Tue, 15 Sep 2020 03:21:52 GMT
Cache-Control: no-cache
Expires: Tue, 15 Sep 2020 03:21:52 GMT
Date: Tue, 15 Sep 2020 03:21:52 GMT
Pragma: no-cache
X-Content-Type-Options: nosniff
X-FRAME-OPTIONS: SAMEORIGIN
X-XSS-Protection: 1; mode=block
Set-Cookie: hadoop.auth="u=cloudera&p=cloudera&t=simple&e=1600176112121&s=CsVEvtX1nS9tc10oRreBDa/eulK/7UlNQGWz/zPslk8="; Path=/; HttpOnly
Location: http://cdh6:9864/webhdfs/v1/user/cloudera/testdir/passwd?op=CREATE&user.name=cloudera&namenoderpcaddress=cdh6:8020&createflag=&createparent=true&overwrite=false
                --9864是datanode的WebHUI port
Content-Type: application/octet-stream
Content-Length: 0


--檢查put操作的結果
[cloudera@cdh6 ~]$ hdfs dfs -ls /user/cloudera/testdir   
                 --passwd檔案並未出現在預期位置

--將上面curl執行結果所回傳的Location加入下面指令中
[cloudera@cdh6 ~]$ curl -i -X PUT -T /etc/passwd "http://cdh6:50075/webhdfs/v1/user/cloudera/testdir/passwd?op=CREATE&user.name=cloudera&namenoderpcaddress=cdh6:8020&overwrite=false"
HTTP/1.1 100 Continue

HTTP/1.1 201 Created
Location: hdfs://cdh6:8020/user/cloudera/testdir/passwd
Content-Length: 0
Connection: close

[cloudera@cdh6 ~]$ hdfs dfs -ls /user/cloudera/testdir/passwd
-rw-r--r--   1 cloudera cloudera       2604 2019-06-24 01:50 /user/cloudera/testdir/passwd

--檢視HttpFS是否啟動
[root@cdh6 ~]# jps | grep HttpFS
4356 HttpFSServerWebServer

--CM->HDFS->Instances
--是否有Httpfs instance存在
--若不存在,點擊Add Role Instances,選擇將HttpFs安裝在某台主機,並且啟動HttpFs服務

--使用HttpFs時,所連線http主機位置為HttpFs(port:14000)
[cloudera@cdh6 ~]$ curl -i -L "http://cdh6:14000/webhdfs/v1/user/cloudera/passwd?op=OPEN&user.name=cloudera"
HTTP/1.1 200 OK
Date: Tue, 15 Sep 2020 03:33:41 GMT
Cache-Control: no-cache
Expires: Tue, 15 Sep 2020 03:33:41 GMT
Date: Tue, 15 Sep 2020 03:33:41 GMT
Pragma: no-cache
Content-Type: application/octet-stream
X-Content-Type-Options: nosniff
X-XSS-Protection: 1; mode=block
Set-Cookie: hadoop.auth="u=cloudera&p=cloudera&t=simple-dt&e=1600176821145&s=iwK4mkFKXY2k+I/dEUg0hsshHH98jggxJ5ycP0QTP9A="; Path=/; HttpOnly
Content-Length: 3509

root:x:0:0:root:/root:/bin/bash
bin:x:1:1:bin:/bin:/sbin/nologin
daemon:x:2:2:daemon:/sbin:/sbin/nologin
adm:x:3:4:adm:/var/adm:/sbin/nologin
lp:x:4:7:lp:/var/spool/lpd:/sbin/nologin
sync:x:5:0:sync:/sbin:/bin/sync
shutdown:x:6:0:shutdown:/sbin:/sbin/shutdown

--使用HttpFs上傳本地檔案,需要加上--header "Content-Type:application/octet-stream",方能成功 
[cloudera@cdh6 ~]$ curl -i -X PUT -T /etc/passwd "http://cdh6:14000/webhdfs/v1/user/cloudera/testdir/passwd1?op=CREATE&user.name=cloudera&data=true" --header "Content-Type:application/octet-stream"
HTTP/1.1 100 Continue

HTTP/1.1 201 Created
Date: Tue, 15 Sep 2020 03:34:32 GMT
Cache-Control: no-cache
Expires: Tue, 15 Sep 2020 03:34:32 GMT
Date: Tue, 15 Sep 2020 03:34:32 GMT
Pragma: no-cache
Content-Type: application/json;charset=utf-8
X-Content-Type-Options: nosniff
X-XSS-Protection: 1; mode=block
Set-Cookie: hadoop.auth="u=cloudera&p=cloudera&t=simple-dt&e=1600176872877&s=ipFu+5VBRGub944+0ZcsU/5p1iGK4vmU1WQM3k9o440="; Path=/; HttpOnly
Content-Length: 0

[cloudera@cdh6 ~]$ hdfs dfs -ls /user/cloudera/testdir/                            
Found 2 items
-rw-r--r--   1 cloudera cloudera       2652 2019-09-23 20:35 /user/cloudera/testdir/passwd
-rwxr-xr-x   1 cloudera cloudera       2652 2019-09-23 21:18 /user/cloudera/testdir/passwd1
\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\
Container Virtual CPU Cores
yarn.nodemanager.resource.cpu-vcores(Number of virtual CPU cores that can be allocated for containers)

Container Memory
yarn.nodemanager.resource.memory-mb(Amount of physical memory, in MiB, that can be allocated for containers)



--MapReduce
--WordCout範例
[cloudera@cdh6 ~]$ ls -l /opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-mapreduce/hadoop-mapreduce-examples.jar
lrwxrwxrwx 1 root root 44 Nov  9  2019 /opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-mapreduce/hadoop-mapreduce-examples.jar -> hadoop-mapreduce-examples-3.0.0-cdh6.3.2.jar

--請注意要被計數的檔案必須存在
--請注意輸出目錄不能事先存在
[cloudera@cdh6 ~]$ hdfs dfs -ls /user/cloudera/shakespeare.txt
-rw-r--r--   1 cloudera cloudera    5444257 2019-08-11 23:19 /user/cloudera/shakespeare.txt
[cloudera@cdh6 ~]$ hdfs dfs -ls /user/cloudera/wordcount_output/
ls: `/user/cloudera/wordcount_output/': No such file or directory

                            此檔案不需要事先上傳到HDFS
                            --------------------------------------------------------------------------------------------------------
[cloudera@cdh6 ~]$ yarn jar /opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-mapreduce/hadoop-mapreduce-examples.jar wordcount /user/cloudera/shakespeare.txt /user/cloudera/wordcount_output/
WARNING: YARN_CONF_DIR has been replaced by HADOOP_CONF_DIR. Using value of YARN_CONF_DIR.
WARNING: YARN_OPTS has been replaced by HADOOP_OPTS. Using value of YARN_OPTS.
20/09/15 14:08:56 INFO client.RMProxy: Connecting to ResourceManager at cdh6/192.168.56.103:8032
20/09/15 14:08:57 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /user/cloudera/.staging/job_1600045559460_0011
20/09/15 14:08:57 INFO input.FileInputFormat: Total input files to process : 1
20/09/15 14:08:57 INFO mapreduce.JobSubmitter: number of splits:1
20/09/15 14:08:57 INFO Configuration.deprecation: yarn.resourcemanager.system-metrics-publisher.enabled is deprecated. Instead, use yarn.system-metrics-publisher.enabled
20/09/15 14:08:57 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1600045559460_0011
20/09/15 14:08:57 INFO mapreduce.JobSubmitter: Executing with tokens: []
20/09/15 14:08:57 INFO conf.Configuration: resource-types.xml not found
20/09/15 14:08:57 INFO resource.ResourceUtils: Unable to find 'resource-types.xml'.
20/09/15 14:08:57 INFO impl.YarnClientImpl: Submitted application application_1600045559460_0011
20/09/15 14:08:57 INFO mapreduce.Job: The url to track the job: http://cdh6:8088/proxy/application_1600045559460_0011/
20/09/15 14:08:57 INFO mapreduce.Job: Running job: job_1600045559460_0011
20/09/15 14:09:03 INFO mapreduce.Job: Job job_1600045559460_0011 running in uber mode : false
20/09/15 14:09:03 INFO mapreduce.Job:  map 0% reduce 0%
20/09/15 14:09:09 INFO mapreduce.Job:  map 100% reduce 0%
20/09/15 14:09:15 INFO mapreduce.Job:  map 100% reduce 100%
20/09/15 14:09:16 INFO mapreduce.Job: Job job_1600045559460_0011 completed successfully
20/09/15 14:09:16 INFO mapreduce.Job: Counters: 54
        File System Counters
                FILE: Number of bytes read=495847
                FILE: Number of bytes written=1651531
                FILE: Number of read operations=0
                FILE: Number of large read operations=0
                FILE: Number of write operations=0
                HDFS: Number of bytes read=5436646
                HDFS: Number of bytes written=713484
                HDFS: Number of read operations=13
                HDFS: Number of large read operations=0
                HDFS: Number of write operations=4
                HDFS: Number of bytes read erasure-coded=0
        Job Counters
                Launched map tasks=1                                              --因為檔案只有一個hdfs block
                Launched reduce tasks=2                                           --reducer預設為2
                Data-local map tasks=1
                Total time spent by all maps in occupied slots (ms)=3515
                Total time spent by all reduces in occupied slots (ms)=5623
                Total time spent by all map tasks (ms)=3515
                Total time spent by all reduce tasks (ms)=5623
                Total vcore-milliseconds taken by all map tasks=3515
                Total vcore-milliseconds taken by all reduce tasks=5623
                Total megabyte-milliseconds taken by all map tasks=3599360
                Total megabyte-milliseconds taken by all reduce tasks=5757952
        Map-Reduce Framework
                Map input records=124192
                Map output records=899594
                Map output bytes=8528714
                Map output materialized bytes=495842
                Input split bytes=111
                Combine input records=899594
                Combine output records=67107
                Reduce input groups=67107
                Reduce shuffle bytes=495842
                Reduce input records=67107
                Reduce output records=67107
                Spilled Records=134214
                Shuffled Maps =2
                Failed Shuffles=0
                Merged Map outputs=2
                GC time elapsed (ms)=170
                CPU time spent (ms)=6340
                Physical memory (bytes) snapshot=965980160
                Virtual memory (bytes) snapshot=7817494528
                Total committed heap usage (bytes)=1053818880
                Peak Map Physical memory (bytes)=531963904
                Peak Map Virtual memory (bytes)=2595655680
                Peak Reduce Physical memory (bytes)=220274688
                Peak Reduce Virtual memory (bytes)=2612785152
        Shuffle Errors
                BAD_ID=0
                CONNECTION=0
                IO_ERROR=0
                WRONG_LENGTH=0
                WRONG_MAP=0
                WRONG_REDUCE=0
        File Input Format Counters
                Bytes Read=5436535
        File Output Format Counters
                Bytes Written=713484

[cloudera@cdh6 ~]$ hdfs dfs -ls /user/cloudera/wordcount_output/
Found 3 items
-rw-r--r--   1 cloudera supergroup          0 2020-09-15 14:09 /user/cloudera/wordcount_output/_SUCCESS
-rw-r--r--   1 cloudera supergroup     357020 2020-09-15 14:09 /user/cloudera/wordcount_output/part-r-00000
-rw-r--r--   1 cloudera supergroup     356464 2020-09-15 14:09 /user/cloudera/wordcount_output/part-r-00001

[cloudera@cdh6 ~]$ hdfs dfs -tail /user/cloudera/wordcount_output/part-r-00001
ellowing        1
yellowness;     1
yelping 1
yeoman? 2
yeomen! 1
yerk'd  1
yes;    3
yesterday       11
yesterday,      9
yesterday.      2
yesterday:      1
yesternight     7
yesternight,    2
yesternight.    2
yesty   2
yet     930
yet'!   1
yet,    102
yet.    50
yet:    2
yield!  1
yield;  1
yield?  1
yielded 16
yielded,        2
yielded.        2
yielder,        1
yielder-up      1
yielding-       1
yields  12
yok'd   2
yoke    18
yoke,   5
yoke-devils     1
yoke.   1
yoked   3
yoketh  1
yon     14
yond    32
yond,   1
yond.   1
yonder; 1
yonder? 4
you!    94
you'    3
you'-That       1
you'.   1
you'R   1
you'd   11
you'fl  1
you'ld  1
you'll  102
you-    45
you--you        1
you-often       1
you-pray        1
you-well,       1
you.'   4
you.-   5
you;    261
you?    259
young   345
young's 1
young'st        1
young,  36
young-ey'd      1
young.  9
youngest        21
youngest,       1
your-   1
yours   77
yours,  60
yours-- 1
yours-not       1
yours.  63
yours:  4
yourself!       3
yourself;       17
yourself?       9
yourselves!     1
yourselves;     3
yourselves?     4
youth!  6
youth-  3
youth.' 1
youth;  15
youth?  5
youthful        29
youthful,       2
youths  4
youtli  1
zanies. 1
zany,   1
zeal    20
zeal,   7
zeal.   4
zed!    1
zenith  1
zodiac  1
zone,   1
zounds! 1
zwagger'd       1

--常見錯誤,reduce所寫入的hdfs directory或file已經存在
[cloudera@cdh6 ~]$ yarn jar /opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-mapreduce/hadoop-mapreduce-examples.jar wordcount /user/cloudera/shakespeare_1M.txt /user/cloudera/wordcount_output/
WARNING: YARN_CONF_DIR has been replaced by HADOOP_CONF_DIR. Using value of YARN_CONF_DIR.
WARNING: YARN_OPTS has been replaced by HADOOP_OPTS. Using value of YARN_OPTS.
20/09/15 14:12:19 INFO client.RMProxy: Connecting to ResourceManager at cdh6/192.168.56.103:8032
org.apache.hadoop.mapred.FileAlreadyExistsException: Output directory hdfs://cdh6:8020/user/cloudera/wordcount_output already exists   <----
        at org.apache.hadoop.mapreduce.lib.output.FileOutputFormat.checkOutputSpecs(FileOutputFormat.java:164)
        at org.apache.hadoop.mapreduce.JobSubmitter.checkSpecs(JobSubmitter.java:277)
        at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:143)
        at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1570)
        at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1567)
        at java.security.AccessController.doPrivileged(Native Method)
        at javax.security.auth.Subject.doAs(Subject.java:422)
        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1875)
        at org.apache.hadoop.mapreduce.Job.submit(Job.java:1567)
        at org.apache.hadoop.mapreduce.Job.waitForCompletion(Job.java:1588)
        at org.apache.hadoop.examples.WordCount.main(WordCount.java:87)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:498)
        at org.apache.hadoop.util.ProgramDriver$ProgramDescription.invoke(ProgramDriver.java:71)
        at org.apache.hadoop.util.ProgramDriver.run(ProgramDriver.java:144)
        at org.apache.hadoop.examples.ExampleDriver.main(ExampleDriver.java:74)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:498)
        at org.apache.hadoop.util.RunJar.run(RunJar.java:313)
        at org.apache.hadoop.util.RunJar.main(RunJar.java:227)

--針對有多個HDFS Blocks組成的檔案進行workcount
[cloudera@cdh6 ~]$ yarn jar /opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-mapreduce/hadoop-mapreduce-examples.jar wordcount /user/cloudera/shakespeare_1M.txt /user/cloudera/wordcount_output1/
WARNING: YARN_CONF_DIR has been replaced by HADOOP_CONF_DIR. Using value of YARN_CONF_DIR.
WARNING: YARN_OPTS has been replaced by HADOOP_OPTS. Using value of YARN_OPTS.
20/09/15 14:13:31 INFO client.RMProxy: Connecting to ResourceManager at cdh6/192.168.56.103:8032
20/09/15 14:13:32 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /user/cloudera/.staging/job_1600045559460_0012
20/09/15 14:13:32 INFO input.FileInputFormat: Total input files to process : 1
20/09/15 14:13:32 INFO mapreduce.JobSubmitter: number of splits:6
20/09/15 14:13:32 INFO Configuration.deprecation: yarn.resourcemanager.system-metrics-publisher.enabled is deprecated. Instead, use yarn.system-metrics-publisher.enabled
20/09/15 14:13:32 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1600045559460_0012
20/09/15 14:13:32 INFO mapreduce.JobSubmitter: Executing with tokens: []
20/09/15 14:13:32 INFO conf.Configuration: resource-types.xml not found
20/09/15 14:13:32 INFO resource.ResourceUtils: Unable to find 'resource-types.xml'.
20/09/15 14:13:32 INFO impl.YarnClientImpl: Submitted application application_1600045559460_0012
20/09/15 14:13:32 INFO mapreduce.Job: The url to track the job: http://cdh6:8088/proxy/application_1600045559460_0012/
20/09/15 14:13:32 INFO mapreduce.Job: Running job: job_1600045559460_0012
20/09/15 14:13:37 INFO mapreduce.Job: Job job_1600045559460_0012 running in uber mode : false
20/09/15 14:13:37 INFO mapreduce.Job:  map 0% reduce 0%
20/09/15 14:13:43 INFO mapreduce.Job:  map 33% reduce 0%
20/09/15 14:13:44 INFO mapreduce.Job:  map 50% reduce 0%
20/09/15 14:13:48 INFO mapreduce.Job:  map 83% reduce 0%
20/09/15 14:13:49 INFO mapreduce.Job:  map 100% reduce 0%
20/09/15 14:13:54 INFO mapreduce.Job:  map 100% reduce 100%
20/09/15 14:13:54 INFO mapreduce.Job: Job job_1600045559460_0012 completed successfully
20/09/15 14:13:54 INFO mapreduce.Job: Counters: 54
        File System Counters
                FILE: Number of bytes read=688404
                FILE: Number of bytes written=3396063
                FILE: Number of read operations=0
                FILE: Number of large read operations=0
                FILE: Number of write operations=0
                HDFS: Number of bytes read=5764899
                HDFS: Number of bytes written=713484
                HDFS: Number of read operations=28
                HDFS: Number of large read operations=0
                HDFS: Number of write operations=4
                HDFS: Number of bytes read erasure-coded=0
        Job Counters
                Launched map tasks=6                                           --6個map tasks,因為檔案有6個hdfs blocks
                Launched reduce tasks=2
                Data-local map tasks=6
                Total time spent by all maps in occupied slots (ms)=21704
                Total time spent by all reduces in occupied slots (ms)=5534
                Total time spent by all map tasks (ms)=21704
                Total time spent by all reduce tasks (ms)=5534
                Total vcore-milliseconds taken by all map tasks=21704
                Total vcore-milliseconds taken by all reduce tasks=5534
                Total megabyte-milliseconds taken by all map tasks=22224896
                Total megabyte-milliseconds taken by all reduce tasks=5666816
        Map-Reduce Framework
                Map input records=124192
                Map output records=899594
                Map output bytes=8528714
                Map output materialized bytes=947785
                Input split bytes=684
                Combine input records=899594
                Combine output records=127904
                Reduce input groups=67107
                Reduce shuffle bytes=947785
                Reduce input records=127904
                Reduce output records=67107
                Spilled Records=255808
                Shuffled Maps =12
                Failed Shuffles=0
                Merged Map outputs=12
                GC time elapsed (ms)=830
                CPU time spent (ms)=15450
                Physical memory (bytes) snapshot=3577991168
                Virtual memory (bytes) snapshot=20781117440
                Total committed heap usage (bytes)=4008181760
                Peak Map Physical memory (bytes)=563367936
                Peak Map Virtual memory (bytes)=2598227968
                Peak Reduce Physical memory (bytes)=219549696
                Peak Reduce Virtual memory (bytes)=2609569792
        Shuffle Errors
                BAD_ID=0
                CONNECTION=0
                IO_ERROR=0
                WRONG_LENGTH=0
                WRONG_MAP=0
                WRONG_REDUCE=0
        File Input Format Counters
                Bytes Read=5764215
        File Output Format Counters
                Bytes Written=713484


[cloudera@cdh6 ~]$ hdfs dfs -ls /user/cloudera/wordcount_output1
Found 3 items
-rw-r--r--   1 cloudera supergroup          0 2020-09-15 14:13 /user/cloudera/wordcount_output1/_SUCCESS
-rw-r--r--   1 cloudera supergroup     357020 2020-09-15 14:13 /user/cloudera/wordcount_output1/part-r-00000
-rw-r--r--   1 cloudera supergroup     356464 2020-09-15 14:13 /user/cloudera/wordcount_output1/part-r-00001

--https://archive.cloudera.com/cdh6/
--https://archive.cloudera.com/cm6/
--從6.3.3開始,必須訂閱CDH,才能下載CDH執行檔

--顯示目前執行中YARN applications
[cloudera@cdh6 ~]$ yarn application -list
]WARNING: YARN_CONF_DIR has been replaced by HADOOP_CONF_DIR. Using value of YARN_CONF_DIR.
WARNING: YARN_OPTS has been replaced by HADOOP_OPTS. Using value of YARN_OPTS.
20/09/15 13:41:02 INFO client.RMProxy: Connecting to ResourceManager at cdh6/192.168.56.103:8032
Total number of applications (application-types: [], states: [SUBMITTED, ACCEPTED, RUNNING] and tags: []):1
                Application-Id      Application-Name        Application-Type          User           Queue             State              Final-State             Progress                        Tracking-URL
application_1600045559460_0009  Hive on Spark (hiveSessionId = 9985a638-bebf-44ad-bd4c-0d71d693cfb9)                   SPARK         cloudera      root.users.cloudera                RUNNING               UNDEFINED            10%                    http://cdh6:42078

--關閉submit job的視窗並不能結束該job,必須使用yarn application -kill application_id方能在Hadoop cluster端中止該job
[cloudera@cdh6 ~]$ yarn application -kill application_1600045559460_0009
WARNING: YARN_CONF_DIR has been replaced by HADOOP_CONF_DIR. Using value of YARN_CONF_DIR.
WARNING: YARN_OPTS has been replaced by HADOOP_OPTS. Using value of YARN_OPTS.
20/09/15 13:41:36 INFO client.RMProxy: Connecting to ResourceManager at cdh6/192.168.56.103:8032
Killing application application_1600045559460_0009
20/09/15 13:41:36 INFO impl.YarnClientImpl: Killed application application_1600045559460_0009
[cloudera@cdh6 ~]$ yarn application -list
WARNING: YARN_CONF_DIR has been replaced by HADOOP_CONF_DIR. Using value of YARN_CONF_DIR.
WARNING: YARN_OPTS has been replaced by HADOOP_OPTS. Using value of YARN_OPTS.
20/09/15 13:41:41 INFO client.RMProxy: Connecting to ResourceManager at cdh6/192.168.56.103:8032
Total number of applications (application-types: [], states: [SUBMITTED, ACCEPTED, RUNNING] and tags: []):0
                Application-Id      Application-Name        Application-Type          User           Queue             State              Final-State             Progress                        Tracking-URL

[cloudera@cdh6 ~]$ ps -ef |grep proc_
hive       568  1195  0 13:40 ?        00:00:01 /usr/bin/python2 /opt/cloudera/cm-agent/bin/cm proc_watcher 584
hive       569  1195  0 13:40 ?        00:00:01 /usr/bin/python2 /opt/cloudera/cm-agent/bin/cm proc_watcher 586
hive       584   568  1 13:40 ?        00:00:32 /usr/java/jdk1.8.0_232-cloudera/bin/java -Dproc_jar -Djava.net.preferIPv4Stack=true -Djava.net.preferIPv4Stack=true -Xms52428800 -Xmx52428800 -XX:+UseParNewGC -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=/tmp/hive_hive-HIVEMETASTORE-6c57b1a598e149581e1d58acf4880987_pid584.hprof -XX:OnOutOfMemoryError=/opt/cloudera/cm-agent/service/common/killparent.sh -Dlog4j.configurationFile=hive-log4j2.properties -Dlog4j.configurationFile=hive-log4j2.properties -Djava.util.logging.config.file=/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hive/bin/../conf/parquet-logging.properties -Dyarn.log.dir=/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/logs -Dyarn.log.file=hadoop.log -Dyarn.home.dir=/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/libexec/../../hadoop-yarn -Dyarn.root.logger=INFO,console -Djava.library.path=/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/native -Dhadoop.log.dir=/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/logs -Dhadoop.log.file=hadoop.log -Dhadoop.home.dir=/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop -Dhadoop.id.str=hive -Dhadoop.root.logger=INFO,console -Dhadoop.policy.file=hadoop-policy.xml -Dhadoop.security.logger=INFO,NullAppender org.apache.hadoop.util.RunJar /opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hive/lib/hive-service-2.1.1-cdh6.3.2.jar org.apache.hadoop.hive.metastore.HiveMetaStore -p 9083
hive       586   569  0 13:40 ?        00:00:18 /usr/java/jdk1.8.0_232-cloudera/bin/java -Dproc_jar -Djava.net.preferIPv4Stack=true -Djava.net.preferIPv4Stack=true -Xms52428800 -Xmx52428800 -XX:+UseParNewGC -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=/tmp/hive_hive-HIVESERVER2-6c57b1a598e149581e1d58acf4880987_pid586.hprof -XX:OnOutOfMemoryError=/opt/cloudera/cm-agent/service/common/killparent.sh -Dlog4j.configurationFile=hive-log4j2.properties -Dlog4j.configurationFile=hive-log4j2.properties -Djava.util.logging.config.file=/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hive/bin/../conf/parquet-logging.properties -Dyarn.log.dir=/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/logs -Dyarn.log.file=hadoop.log -Dyarn.home.dir=/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/libexec/../../hadoop-yarn -Dyarn.root.logger=INFO,console -Djava.library.path=/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/native -Dhadoop.log.dir=/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/logs -Dhadoop.log.file=hadoop.log -Dhadoop.home.dir=/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop -Dhadoop.id.str=hive -Dhadoop.root.logger=INFO,console -Dhadoop.policy.file=hadoop-policy.xml -Dhadoop.security.logger=INFO,NullAppender org.apache.hadoop.util.RunJar /opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hive/lib/hive-service-2.1.1-cdh6.3.2.jar org.apache.hive.service.server.HiveServer2 --hiveconf hive.aux.jars.path=file:///opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hive/auxlib/hive-exec-2.1.1-cdh6.3.2-core.jar,file:///opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hive/auxlib/hive-exec-core.jar
hue       1651  1195  0 13:41 ?        00:00:01 /usr/bin/python2 /opt/cloudera/cm-agent/bin/cm proc_watcher 1692
hue       1652  1195  0 13:41 ?        00:00:01 /usr/bin/python2 /opt/cloudera/cm-agent/bin/cm proc_watcher 1689
impala    1653  1195  0 13:41 ?        00:00:01 /usr/bin/python2 /opt/cloudera/cm-agent/bin/cm proc_watcher 1691
impala    1654  1195  0 13:41 ?        00:00:01 /usr/bin/python2 /opt/cloudera/cm-agent/bin/cm proc_watcher 1695
impala    2165  1195  0 13:41 ?        00:00:01 /usr/bin/python2 /opt/cloudera/cm-agent/bin/cm proc_watcher 2191
mapred    3003  1195  0 00:45 ?        00:00:01 /usr/bin/python2 /opt/cloudera/cm-agent/bin/cm proc_watcher 3037
yarn      3004  1195  0 00:45 ?        00:00:01 /usr/bin/python2 /opt/cloudera/cm-agent/bin/cm proc_watcher 3050
yarn      3005  1195  0 00:45 ?        00:00:01 /usr/bin/python2 /opt/cloudera/cm-agent/bin/cm proc_watcher 3035
yarn      3035  3005  0 00:45 ?        00:07:14 /usr/java/jdk1.8.0_232-cloudera/bin/java -Dproc_resourcemanager -Djava.net.preferIPv4Stack=true -Xms52428800 -Xmx52428800 -XX:+UseParNewGC -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled -Dlibrary.leveldbjni.path=/var/run/cloudera-scm-agent/process/160-yarn-RESOURCEMANAGER -Dhadoop.event.appender=,EventCatcher -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=/tmp/yarn_yarn-RESOURCEMANAGER-6c57b1a598e149581e1d58acf4880987_pid3035.hprof -XX:OnOutOfMemoryError=/opt/cloudera/cm-agent/service/common/killparent.sh -Dyarn.log.dir=/var/log/hadoop-yarn -Dyarn.log.file=hadoop-cmf-yarn-RESOURCEMANAGER-cdh6.log.out -Dyarn.home.dir=/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-yarn -Dyarn.root.logger=INFO,RFA -Djava.library.path=/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/native -Dhadoop.log.dir=/var/log/hadoop-yarn -Dhadoop.log.file=hadoop-cmf-yarn-RESOURCEMANAGER-cdh6.log.out -Dhadoop.home.dir=/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop -Dhadoop.id.str=yarn -Dhadoop.root.logger=INFO,RFA -Dhadoop.policy.file=hadoop-policy.xml -Dhadoop.security.logger=INFO,NullAppender org.apache.hadoop.yarn.server.resourcemanager.ResourceManager
mapred    3037  3003  0 00:45 ?        00:02:21 /usr/java/jdk1.8.0_232-cloudera/bin/java -Dproc_historyserver -Djava.net.preferIPv4Stack=true -Xms52428800 -Xmx52428800 -XX:+UseParNewGC -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled -Dlibrary.leveldbjni.path=/var/run/cloudera-scm-agent/process/158-yarn-JOBHISTORY -Dhadoop.event.appender=,EventCatcher -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=/tmp/yarn_yarn-JOBHISTORY-6c57b1a598e149581e1d58acf4880987_pid3037.hprof -XX:OnOutOfMemoryError=/opt/cloudera/cm-agent/service/common/killparent.sh -Dyarn.log.dir=/var/log/hadoop-mapreduce -Dyarn.log.file=hadoop-cmf-yarn-JOBHISTORY-cdh6.log.out -Dyarn.home.dir=/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-yarn -Dyarn.root.logger=INFO,console -Djava.library.path=/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/native -Dhadoop.log.dir=/var/log/hadoop-mapreduce -Dhadoop.log.file=hadoop-cmf-yarn-JOBHISTORY-cdh6.log.out -Dhadoop.home.dir=/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop -Dhadoop.id.str=mapred -Dhadoop.root.logger=INFO,RFA -Dhadoop.policy.file=hadoop-policy.xml -Dhadoop.security.logger=INFO,RFAS org.apache.hadoop.mapreduce.v2.hs.JobHistoryServer
yarn      3050  3004  0 00:46 ?        00:04:01 /usr/java/jdk1.8.0_232-cloudera/bin/java -Dproc_nodemanager -Djava.net.preferIPv4Stack=true -Xms52428800 -Xmx52428800 -XX:+UseParNewGC -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled -Dlibrary.leveldbjni.path=/var/run/cloudera-scm-agent/process/159-yarn-NODEMANAGER -Dhadoop.event.appender=,EventCatcher -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=/tmp/yarn_yarn-NODEMANAGER-6c57b1a598e149581e1d58acf4880987_pid3050.hprof -XX:OnOutOfMemoryError=/opt/cloudera/cm-agent/service/common/killparent.sh -Dyarn.log.dir=/var/log/hadoop-yarn -Dyarn.log.file=hadoop-cmf-yarn-NODEMANAGER-cdh6.log.out -Dyarn.home.dir=/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-yarn -Dyarn.root.logger=INFO,RFA -Djava.library.path=/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/native -Dhadoop.log.dir=/var/log/hadoop-yarn -Dhadoop.log.file=hadoop-cmf-yarn-NODEMANAGER-cdh6.log.out -Dhadoop.home.dir=/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop -Dhadoop.id.str=yarn -Dhadoop.root.logger=INFO,RFA -Dhadoop.policy.file=hadoop-policy.xml -Dhadoop.security.logger=INFO,NullAppender org.apache.hadoop.yarn.server.nodemanager.NodeManager
zookeep+  3365  1195  0 00:46 ?        00:00:01 /usr/bin/python2 /opt/cloudera/cm-agent/bin/cm proc_watcher 4092
httpfs    4056  1195  0 00:46 ?        00:00:01 /usr/bin/python2 /opt/cloudera/cm-agent/bin/cm proc_watcher 4356
hdfs      4059  1195  0 00:46 ?        00:00:01 /usr/bin/python2 /opt/cloudera/cm-agent/bin/cm proc_watcher 4417
hdfs      4062  1195  0 00:46 ?        00:00:01 /usr/bin/python2 /opt/cloudera/cm-agent/bin/cm proc_watcher 4419
hdfs      4064  1195  0 00:46 ?        00:00:01 /usr/bin/python2 /opt/cloudera/cm-agent/bin/cm proc_watcher 4433
httpfs    4356  4056  0 00:46 ?        00:00:55 /usr/java/jdk1.8.0_232-cloudera/bin/java -Dproc_httpfs -Dhadoop.log.file=hadoop-cmf-hdfs-HTTPFS-cdh6.log.out -Dhadoop.root.logger=INFO,RFA -Djava.net.preferIPv4Stack=true -Dhttpfs.home.dir=/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-httpfs -Dhttpfs.config.dir=/var/run/cloudera-scm-agent/process/86-hdfs-HTTPFS -Dhttpfs.log.dir=/var/log/hadoop-httpfs -Dhttpfs.temp.dir=/var/run/cloudera-scm-agent/process/86-hdfs-HTTPFS/run/ -Dyarn.log.dir=/var/log/hadoop-httpfs -Dyarn.log.file=hadoop.log -Dyarn.home.dir=/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-yarn -Dyarn.root.logger=INFO,console -Djava.library.path=/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/native -Dhadoop.log.dir=/var/log/hadoop-httpfs -Dhadoop.home.dir=/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop -Dhadoop.id.str=httpfs -Dhadoop.policy.file=hadoop-policy.xml -Dhadoop.security.logger=INFO,NullAppender org.apache.hadoop.fs.http.server.HttpFSServerWebServer
hdfs      4417  4059  0 00:46 ?        00:02:30 /usr/java/jdk1.8.0_232-cloudera/bin/java -Dproc_datanode -Dhdfs.audit.logger=INFO,RFAAUDIT -Dsecurity.audit.logger=INFO,RFAS -Djava.net.preferIPv4Stack=true -Xms955252736 -Xmx955252736 -XX:+UseParNewGC -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=/tmp/hdfs_hdfs-DATANODE-6c57b1a598e149581e1d58acf4880987_pid4417.hprof -XX:OnOutOfMemoryError=/opt/cloudera/cm-agent/service/common/killparent.sh -Dyarn.log.dir=/var/log/hadoop-hdfs -Dyarn.log.file=hadoop-cmf-hdfs-DATANODE-cdh6.log.out -Dyarn.home.dir=/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-yarn -Dyarn.root.logger=INFO,console -Djava.library.path=/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/native -Dhadoop.log.dir=/var/log/hadoop-hdfs -Dhadoop.log.file=hadoop-cmf-hdfs-DATANODE-cdh6.log.out -Dhadoop.home.dir=/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop -Dhadoop.id.str=hdfs -Dhadoop.root.logger=INFO,RFA -Dhadoop.policy.file=hadoop-policy.xml -Dhadoop.security.logger=INFO,RFAS org.apache.hadoop.hdfs.server.datanode.DataNode
hdfs      4419  4062  0 00:46 ?        00:01:26 /usr/java/jdk1.8.0_232-cloudera/bin/java -Dproc_secondarynamenode -Dhdfs.audit.logger=INFO,RFAAUDIT -Dsecurity.audit.logger=INFO,RFAS -Djava.net.preferIPv4Stack=true -Xms955252736 -Xmx955252736 -XX:+UseParNewGC -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=/tmp/hdfs_hdfs-SECONDARYNAMENODE-6c57b1a598e149581e1d58acf4880987_pid4419.hprof -XX:OnOutOfMemoryError=/opt/cloudera/cm-agent/service/common/killparent.sh -Dyarn.log.dir=/var/log/hadoop-hdfs -Dyarn.log.file=hadoop-cmf-hdfs-SECONDARYNAMENODE-cdh6.log.out -Dyarn.home.dir=/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-yarn -Dyarn.root.logger=INFO,console -Djava.library.path=/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/native -Dhadoop.log.dir=/var/log/hadoop-hdfs -Dhadoop.log.file=hadoop-cmf-hdfs-SECONDARYNAMENODE-cdh6.log.out -Dhadoop.home.dir=/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop -Dhadoop.id.str=hdfs -Dhadoop.root.logger=INFO,RFA -Dhadoop.policy.file=hadoop-policy.xml -Dhadoop.security.logger=INFO,RFAS org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode
hdfs      4433  4064  0 00:46 ?        00:04:16 /usr/java/jdk1.8.0_232-cloudera/bin/java -Dproc_namenode -Dhdfs.audit.logger=INFO,RFAAUDIT -Dsecurity.audit.logger=INFO,RFAS -Djava.net.preferIPv4Stack=true -Xms955252736 -Xmx955252736 -XX:+UseParNewGC -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=/tmp/hdfs_hdfs-NAMENODE-6c57b1a598e149581e1d58acf4880987_pid4433.hprof -XX:OnOutOfMemoryError=/opt/cloudera/cm-agent/service/common/killparent.sh -Dyarn.log.dir=/var/log/hadoop-hdfs -Dyarn.log.file=hadoop-cmf-hdfs-NAMENODE-cdh6.log.out -Dyarn.home.dir=/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-yarn -Dyarn.root.logger=INFO,console -Djava.library.path=/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/native -Dhadoop.log.dir=/var/log/hadoop-hdfs -Dhadoop.log.file=hadoop-cmf-hdfs-NAMENODE-cdh6.log.out -Dhadoop.home.dir=/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop -Dhadoop.id.str=hdfs -Dhadoop.root.logger=INFO,RFA -Dhadoop.policy.file=hadoop-policy.xml -Dhadoop.security.logger=INFO,RFAS org.apache.hadoop.hdfs.server.namenode.NameNode
clouder+  4440  1195  0 00:46 ?        00:00:01 /usr/bin/python2 /opt/cloudera/cm-agent/bin/cm proc_watcher 4880
clouder+  4443  1195  0 00:46 ?        00:00:01 /usr/bin/python2 /opt/cloudera/cm-agent/bin/cm proc_watcher 4937
clouder+  4452  1195  0 00:46 ?        00:00:01 /usr/bin/python2 /opt/cloudera/cm-agent/bin/cm proc_watcher 4960
clouder+  4459  1195  0 00:46 ?        00:00:01 /usr/bin/python2 /opt/cloudera/cm-agent/bin/cm proc_watcher 4814
spark     4800  1195  0 04:57 ?        00:00:01 /usr/bin/python2 /opt/cloudera/cm-agent/bin/cm proc_watcher 4808
clouder+  4824  1195  0 00:46 ?        00:00:01 /usr/bin/python2 /opt/cloudera/cm-agent/bin/cm proc_watcher 5364
clouder+  4826  1195  0 00:46 ?        00:00:01 /usr/bin/python2 /opt/cloudera/cm-agent/bin/cm proc_watcher 5252
cloudera 12054 17221  0 14:19 pts/1    00:00:00 grep --color=auto proc_


[cloudera@cdh6 ~]$ jps
27792 Jps
[root@cdh6 ~]# jps
4960 Main
4417 DataNode
4419 SecondaryNameNode
11108 -- process information unavailable
5252 AlertPublisher
4356 HttpFSServerWebServer
12166 Jps
4808 HistoryServer
584 RunJar
4937 EventCatcherService
3050 NodeManager
586 RunJar
1230 Main
4814 Main
4880 Main
4433 NameNode
5364 HeadlampServer
3035 ResourceManager
1691
4092 QuorumPeerMain
3037 JobHistoryServer
1695

[cloudera@cdh6 ~]$ hdfs dfs -ls /user/cloudera
Found 13 items
drwx------   - cloudera supergroup          0 2020-09-15 12:00 /user/cloudera/.Trash
drwxr-xr-x   - cloudera supergroup          0 2020-09-15 14:05 /user/cloudera/.sparkStaging
drwx------   - cloudera supergroup          0 2020-09-15 14:13 /user/cloudera/.staging
drwxr-xr-x   - cloudera supergroup          0 2020-09-14 16:19 /user/cloudera/customers
-rw-r--r--   1 cloudera supergroup        617 2020-09-08 15:09 /user/cloudera/emp1.csv
-rw-r--r--   1 cloudera supergroup       3509 2020-09-15 11:16 /user/cloudera/passwd
-rw-r--r--   1 cloudera supergroup    5436535 2020-09-14 14:14 /user/cloudera/shakespeare.txt
-rw-r--r--   1 cloudera supergroup    5436535 2020-09-14 14:15 /user/cloudera/shakespeare_1M.txt
-rw-r--r--   1 cloudera supergroup  227893062 2020-09-14 13:42 /user/cloudera/spark-2.4.0-bin-hadoop2.7.tgz
-rw-r--r--   1 cloudera supergroup     121627 2020-09-14 14:28 /user/cloudera/summer_night.txt
drwxr-xr-x   - cloudera supergroup          0 2020-09-15 11:34 /user/cloudera/testdir
drwxr-xr-x   - cloudera supergroup          0 2020-09-15 14:09 /user/cloudera/wordcount_output
drwxr-xr-x   - cloudera supergroup          0 2020-09-15 14:13 /user/cloudera/wordcount_output1
               owner    group 

檔案僅有rw
目錄才有rwx(x表示對此目錄之下的檔案有r權限)

Hadoop沒有身分驗證機制,所以Hadoop相信hadoop client所在OS所傳來的username
[cloudera@cdh6 ~]$ id
uid=501(cloudera) gid=501(cloudera) groups=501(cloudera),502(default)

[cloudera@cdh6 ~]$ ls -l /etc/hadoop/conf/
total 48
-rw-r--r-- 1 root root     20 Sep 22 22:49 __cloudera_generation__
-rw-r--r-- 1 root root     67 Sep 22 22:49 __cloudera_metadata__
-r-------- 1 root hadoop    0 Sep 23 20:07 container-executor.cfg
-rw-r--r-- 1 root root   3862 Sep 22 22:49 core-site.xml
-rw-r--r-- 1 root root    616 Sep 22 22:49 hadoop-env.sh
-rw-r--r-- 1 root root   1772 Sep 22 22:49 hdfs-site.xml
-rw-r--r-- 1 root root    314 Sep 22 22:49 log4j.properties
-rw-r--r-- 1 root root   5101 Sep 22 22:49 mapred-site.xml
-rw-r--r-- 1 root root    315 Sep 22 22:49 ssl-client.xml
-rw-r--r-- 1 root hadoop  200 Sep 23 22:17 topology.map
-rwxr-xr-x 1 root hadoop 1594 Sep 23 20:07 topology.py
-rw-r--r-- 1 root root   3608 Sep 22 22:49 yarn-site.xml
[cloudera@cdh6 ~]$ ls -l /etc/spark/conf/
total 52
-rw-r--r-- 1 root root 27502 Sep 22 22:49 classpath.txt
-rw-r--r-- 1 root root    21 Sep 22 22:49 __cloudera_generation__
-rw-r--r-- 1 root root    67 Sep 22 22:49 __cloudera_metadata__
-rw-r--r-- 1 root root   951 Sep 22 22:49 log4j.properties
-rw-r--r-- 1 root root     0 Sep 22 22:49 navigator.lineage.client.properties
-rw-r--r-- 1 root root  1632 Sep 22 22:49 spark-defaults.conf
-rw-r--r-- 1 root root  2299 Sep 22 22:49 spark-env.sh
drwxr-xr-x 2 root root  4096 Sep 22 22:49 yarn-conf
[cloudera@cdh6 ~]$ ls -l /etc/hive/conf/
total 60
-rw-r--r-- 1 root root   21 Sep 22 22:49 __cloudera_generation__
-rw-r--r-- 1 root root   67 Sep 22 22:49 __cloudera_metadata__
-rw-r--r-- 1 root root 3862 Sep 22 22:49 core-site.xml
-rw-r--r-- 1 root root  616 Sep 22 22:49 hadoop-env.sh
-rw-r--r-- 1 root root 1772 Sep 22 22:49 hdfs-site.xml
-rw-r--r-- 1 root root 2825 Sep 22 22:49 hive-env.sh
-rw-r--r-- 1 root root 5402 Sep 22 22:49 hive-site.xml
-rw-r--r-- 1 root root  310 Sep 22 22:49 log4j.properties
-rw-r--r-- 1 root root 5101 Sep 22 22:49 mapred-site.xml
-rw-r--r-- 1 root root    0 Sep 22 22:49 redaction-rules.json
-rw-r--r-- 1 root root  315 Sep 22 22:49 ssl-client.xml
-rw-r--r-- 1 root root  200 Sep 22 22:49 topology.map
-rwxr-xr-x 1 root root 1594 Sep 22 22:49 topology.py
-rw-r--r-- 1 root root 3608 Sep 22 22:49 yarn-site.xml
[cloudera@cdh6 ~]$ ls -l /etc/sqoop/conf/
total 20
-rw-r--r-- 1 root root   21 Sep 23 20:11 __cloudera_generation__
-rw-r--r-- 1 root root   67 Sep 23 20:11 __cloudera_metadata__
drwxr-xr-x 2 root root 4096 Sep 23 20:11 managers.d
-rw-r--r-- 1 root root  139 Sep 23 20:11 sqoop-env.sh
-rw-r--r-- 1 root root  288 Sep 23 20:11 sqoop-site.xml

[cloudera@cdh6 ~]$ whoami
cloudera
[cloudera@cdh6 ~]$ hdfs dfs -ls    
--預設HDFS家目錄為/user/cloudera
Found 14 items
drwx------   - cloudera cloudera          0 2019-09-23 22:00 .Trash
drwxr-xr-x   - cloudera cloudera          0 2019-06-28 01:20 .sparkStaging
drwx------   - cloudera cloudera          0 2019-09-23 22:52 .staging
-rw-r--r--   1 cloudera cloudera         80 2019-06-26 22:30 dept1.csv
-rw-r--r--   1 cloudera cloudera        650 2019-06-26 08:34 emp.csv
-rw-r--r--   1 cloudera cloudera        617 2019-06-26 19:38 emp1.csv
-rw-r--r--   1 cloudera cloudera       2652 2019-09-23 20:14 passwd
-rwxr-xr-x   1 cloudera cloudera       2652 2019-09-23 21:17 passwd1
drwxr-xr-x   - cloudera cloudera          0 2019-09-23 19:09 retail_db
-rw-r--r--   1 cloudera cloudera    5444257 2019-09-23 00:18 shakespeare.txt
-rw-r--r--   1 cloudera cloudera    5444257 2019-09-23 00:28 shakespeare_1M.txt
drwxr-xr-x   - cloudera cloudera          0 2019-09-23 21:18 testdir
drwxr-xr-x   - cloudera cloudera          0 2019-09-23 22:50 wordcount_output
drwxr-xr-x   - cloudera cloudera          0 2019-09-23 22:52 wordcount_output1

[cloudera@cdh6 ~]$ su - frank
su: user frank does not exist
[cloudera@cdh6 ~]$ sudo useradd frank
[cloudera@cdh6 ~]$ sudo passwd frank
Changing password for user frank.
New password: cloudera
BAD PASSWORD: it is based on a dictionary word
Retype new password: cloudera
passwd: all authentication tokens updated successfully.
[cloudera@cdh6 ~]$ su - frank
Password: cloudera
[frank@quickstart ~]$ whoami
frank

[cloudera@cdh6 ~]$ su - frank
Password:
[frank@cdh6 ~]$ whoami
frank
[frank@cdh6 ~]$ hdfs dfs -ls
ls: `.': No such file or directory  --因為預設目錄為/user/frank
[frank@cdh6 ~]$ hdfs dfs -ls /
Found 6 items
drwxrwxrwx   - hdfs  supergroup          0 2017-10-23 09:15 /benchmarks
drwxr-xr-x   - hbase supergroup          0 2019-09-23 20:07 /hbase
drwxr-xr-x   - solr  solr                0 2017-10-23 09:18 /solr
drwxrwxrwt   - hdfs  supergroup          0 2019-09-23 02:04 /tmp
drwxr-xr-x   - hdfs  supergroup          0 2017-10-23 09:17 /user
drwxr-xr-x   - hdfs  supergroup          0 2017-10-23 09:17 /var

[frank@cdh6 ~]$ hdfs dfs -mkdir /user/frank
mkdir: Permission denied: user=frank, access=WRITE, inode="/user":hdfs:supergroup:drwxr-xr-x

[frank@cdh6 ~]$ exit
logout
[cloudera@cdh6 ~]$ sudo su - hdfs
-bash-4.1$ whoami
hdfs
-bash-4.1$ hdfs dfs -mkdir /user/frank/
-bash-4.1$ hdfs dfs -chown frank /user/frank
-bash-4.1$ exit
logout
[cloudera@cdh6 ~]$ su - frank
Password:
[frank@quickstart ~]$ hdfs dfs -ls
[frank@quickstart ~]$ hdfs dfs -ls /user
Found 9 items
drwxr-xr-x   - cloudera cloudera            0 2019-09-23 22:51 /user/cloudera
drwxr-xr-x   - frank    supergroup          0 2019-09-23 23:25 /user/frank
drwxr-xr-x   - mapred   hadoop              0 2019-04-22 22:44 /user/history
drwxrwxrwx   - hive     supergroup          0 2017-10-23 09:17 /user/hive
drwxrwxrwx   - hue      supergroup          0 2019-04-22 22:45 /user/hue
drwxrwxrwx   - jenkins  supergroup          0 2017-10-23 09:15 /user/jenkins
drwxrwxrwx   - oozie    supergroup          0 2017-10-23 09:16 /user/oozie
drwxrwxrwx   - root     supergroup          0 2017-10-23 09:16 /user/root
drwxr-xr-x   - hdfs     supergroup          0 2019-06-26 08:31 /user/spark
