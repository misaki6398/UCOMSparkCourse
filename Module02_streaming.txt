$ pyspark

--SparkStreaming
>>> from pyspark.streaming import StreamingContext
>>> ssc = StreamingContext(sc,2) #每2秒截斷串流一次,將其變成DStream
>>> logs = ssc.socketTextStream('cdh6',9999)
>>> userreqs = logs.map(lambda line: (line.split(' ')[2],1)).reduceByKey(lambda v1,v2: v1+v2)
>>> userreqs.pprint()
>>> ssc.start()  #已經開始接受localhost:9999的輸入

=========================================================================================================================
--Console畫面

-------------------------------------------
Time: 2019-09-25 23:15:42
-------------------------------------------

-------------------------------------------
Time: 2019-09-25 23:15:44                     --即便沒有資料,也每2秒產生micro-batch進行操作1次
-------------------------------------------

-------------------------------------------
Time: 2019-09-25 23:15:46
-------------------------------------------

-------------------------------------------
Time: 2019-09-25 23:15:48
-------------------------------------------

-------------------------------------------
Time: 2019-09-25 23:15:50
-------------------------------------------

-------------------------------------------
Time: 2019-09-25 23:15:52
-------------------------------------------

-------------------------------------------
Time: 2019-09-25 23:15:54
-------------------------------------------

-------------------------------------------
Time: 2019-09-25 23:15:56
-------------------------------------------

=========================================================================================================================
$ nc -lk 9999

接著輸入下列內容
I've never seen a purple cow.
I never hope to see one;
But I can tell you, anyhow,
I'd rather see than be one.

\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\
--回到spark2-submit的Terminal

-------------------------------------------
Time: 2019-09-25 23:15:58
-------------------------------------------

-------------------------------------------
Time: 2019-09-25 23:16:00
-------------------------------------------


-------------------------------------------
Time: 2019-09-25 23:16:02
-------------------------------------------
(u'seen', 1)
(u'can', 1)
(u'see', 1)
(u'hope', 1)

-------------------------------------------
Time: 2019-09-25 23:16:04
-------------------------------------------

-------------------------------------------
Time: 2019-09-25 23:16:06
-------------------------------------------

-------------------------------------------
Time: 2019-09-25 23:16:08
-------------------------------------------

-------------------------------------------
Time: 2019-09-25 23:16:10
-------------------------------------------

>>> ssc.stop()

=========================================================================================================================
--Structured Streaming
[cloudera@cdh6 ~]$ cat wordcount_streaming.py
from pyspark.sql import SparkSession
from pyspark.sql.functions import explode
from pyspark.sql.functions import split
spark = SparkSession.builder.appName("StructuredNetworkWordCount").getOrCreate()
lines = spark.readStream.format("socket").option("host", "cdh6").option("port", 12345).load()
words = lines.select(explode(split(lines.value, " ")).alias("word"))
wordCounts = words.groupBy("word").count()
query = wordCounts.writeStream.outputMode("complete").format("console").start()
query.awaitTermination()


\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\
另一個視窗
$ nc -lk 12345
--沒有輸入

===========================================================================================================
-------------------------------------------
Batch: 0
-------------------------------------------
+----+-----+

|word|count|

+----+-----+
+----+-----+

$ nc -lk 12345
I've never seen a purple cow.
I never hope to see one;
But I can tell you, anyhow,
I'd rather see than be one.

+-------+-----+
|   word|count|
+-------+-----+
|   hope|    1|
|    But|    1|
|    I'd|    1|
|   cow.|    1|
|   seen|    1|
|    can|    1|
| rather|    1|
|   tell|    1|
|anyhow,|    1|
|     be|    1|
|   than|    1|
|   one.|    1|
| purple|    1|
|   I've|    1|
|   you,|    1|
|   one;|    1|
|    see|    2|
|  never|    2|
|      I|    2|
|      a|    1|
+-------+-----+
only showing top 20 rows
